{
    "docs": [
        {
            "location": "/",
            "text": "The Gravity Modeling Environment (GME) package is a collection of tools written in Python to be used for gravity trade analysis.  The package consists of tools to aid in the fast, flexible, and robust estimation of gravity models using modern, best practices.  Future updates to the package will include tools for the simulation of general equilibrium gravity models and the preparation of data for estimation.\n\n\nThe GME package offers several distinct advantages over alternative software choices for conducting gravity analysis.  First, the package is written in Python, a flexible, powerful, and free programming language that can be readily used on a wide variety of computers with no cost. Second, unlike more general statistical software, which must cater to a broad number of needs, the GME package has been specifically designed to perform gravity analysis well. Third, because the tools are implemented in Python, users have access to an enormous and growing collection of third-party tools to incorporate into and expand their work.\n\n\nVisit the \nUSITC gravity portal\n for more information about the Gravity Modeling Environment, which includes the GME package and a collection of data.\n\n\nIn the current release, the GME package consists of three key components: the EstimationData object, the EstimationModel object, and the estimate() function. The EstimationData object houses the data to be used for estimation as well as information about the data and a set of tools to facilitate descriptive analysis of the data. The EstimationModel object is used to set up the specification for the estimation of the model and store the eventual results and diagnostic information. Finally, the function estimate() runs a Poisson Pseudo-Maximum Likelihood (PPML) estimation according to the specification established in the EstimationModel.",
            "title": "Introduction"
        },
        {
            "location": "/getting_started/",
            "text": "Getting Started\n\n\nPreparing the Software\n\n\nDependencies\n\n\nThe GME package requires pandas, statsmodels, patsy, and scipy packages. If not already present on your system, they will be automatically installed when installing GME.\n\n\nInstallation\n\n\nDownload and install the GME package.\n\n\npip\n \ninstall\n \ngme\n\n\n\n\n\nA Basic Example: Run PPML estimation\n\n\nStep 1. Import the needed packages\n\n\nimport\n \ngme\n \nas\n \ngme\n\n\nimport\n \npandas\n \nas\n \npd\n\n\n\n\n\nStep 2. Create EstimationData\n\n\nThe GME package is built upon a specialized data object called EstimationData. EstimationData contains data in a \nPandas DataDrame\n as well as a collection of additional information and tools that are useful for gravity modeling, such as \n\n\n\n\nA log of the history of the data, such as the location of the file it was read from and modifications made to it,\n\n\nMetadata, such as names of the columns containing importer, exporter, and year information, so that they need not be continuously supplied,\n\n\nSeveral tools for producing summary statistics or other types of commonly sought descriptive information.\n\n\n\n\nBegin by loading example trade data.  The dataset used in the following code is \navailable for download\n or can be accessed directly with python and pandas, as shown below.\n\n\nsample_data\n \n=\n \npd\n.\nread_csv\n(\n\n    \n'https://www.usitc.gov/data/gravity/example_trade_and_grav_data_small.csv'\n)\n\n\nprint\n(\nsample_data\n.\nhead\n())\n\n\n\nThe first command above reads the data file into memory while the second shows the column names and first 5 lines of the data file.\n\n  importer exporter  year   trade_value  agree_pta  common_language  \\\n\n\n0      AUS      BRA  1989  3.035469e+08        0.0              1.0   \n\n\n1      AUS      CAN  1989  8.769946e+08        0.0              1.0   \n\n\n2      AUS      CHE  1989  4.005245e+08        0.0              1.0   \n\n\n3      AUS      DEU  1989  2.468977e+09        0.0              0.0   \n\n\n4      AUS      DNK  1989  1.763072e+08        0.0              1.0   \n\n\n   contiguity  log_distance  \n\n\n0         0.0      9.553332  \n\n\n1         0.0      9.637676  \n\n\n2         0.0      9.687557  \n\n\n3         0.0      9.675007  \n\n\n4         0.0      9.657311 \n\n\n\n\nNext, create an instance of the EstimationData object using the sample data. To create an EstimationData instance (called gme_data in the example below), you need to supply a Pandas DataFrame and identifiers for certain key columns, such as the trade flows, importer/exporter, year, and sector (if applicable).\n\n\ngme_data\n \n=\n \ngme\n.\nEstimationData\n(\ndata_frame\n \n=\n \nsample_data\n,\n\n                              \nimp_var_name\n \n=\n \n'importer'\n,\n\n                              \nexp_var_name\n \n=\n \n'exporter'\n,\n\n                              \ntrade_var_name\n \n=\n \n'trade_value'\n,\n\n                              \nyear_var_name\n \n=\n \n'year'\n)\n\n\nprint\n(\ngme_data\n)\n\n\n\nThe print command above produces basic summary statistics, contained in a printable representation of the EstimationData class:\n\n\nnumber of countries: 62 \n\n\nnumber of exporters: 62 \n\n\nnumber of importers: 62 \n\n\nnumber of years: 27 \n\n\nnumber of sectors: not_applicable \n\n\ndimensions: (98612, 8)\n\n\n\n\n\nStep 3. Create an EstimationModel\n\n\nAfter creating an EstimationData object, you need to create an EstimationModel object, which will be used to produce gravity estimates.  To create an EstimationModel instance (called gme_model in the example below), you need to supply an EstimationData object and a specification.\n\n\ngme_model\n \n=\n \ngme\n.\nEstimationModel\n(\nestimation_data\n \n=\n \ngme_data\n,\n\n                                \nlhs_var\n \n=\n \n'trade_value'\n,\n\n                                \nrhs_var\n \n=\n \n[\n'log_distance'\n,\n'agree_pta'\n,\n'common_language'\n,\n'contiguity'\n],\n\n                                \nfixed_effects\n \n=\n \n[\n'importer'\n,\n \n'exporter'\n],\n\n                                \nkeep_years\n \n=\n \n[\n2015\n])\n\n\n\n\n\nThe initialization of EstimationModel establishes a reference to the EstimationData object rather than a copy of the data.\n\n\nStep 4. Estimate the model\n\n\nWhat is a method?\nA method is a function that is connected only to a particular object. \nClick here to see the relevant Python documentation.\nOnce the EstimationModel is defined, it can be estimated by applying the method .estimate()\n\n\ngme_model\n.\nestimate\n()\n\n\n\n\n\nThe code provides some information while it is running:\n\n\nselect specification variables: ['log_distance', 'agree_pta', 'common_language', 'contiguity', 'trade_value', 'importer', 'exporter', 'year'], Observations excluded by user: {'rows': 0, 'columns': 0}\n\n\ndrop_intratrade: no, Observations excluded by user: {'rows': 0, 'columns': 0}\n\n\ndrop_imp: none, Observations excluded by user: {'rows': 0, 'columns': 0}\n\n\ndrop_exp: none, Observations excluded by user: {'rows': 0, 'columns': 0}\n\n\nkeep_imp: all available, Observations excluded by user: {'rows': 0, 'columns': 0}\n\n\nkeep_exp: all available, Observations excluded by user: {'rows': 0, 'columns': 0}\n\n\ndrop_years: none, Observations excluded by user: {'rows': 0, 'columns': 0}\n\n\nkeep_years: [2015], Observations excluded by user: {'rows': 94952, 'columns': 0}\n\n\ndrop_missing: yes, Observations excluded by user: {'rows': 0, 'columns': 0}\n\n\nEstimation began at 08:09 AM  on Oct 16, 2018\n\n\nOmitted Columns: ['importer_fe_ARG', 'importer_fe_AUT', 'importer_fe_BEL', 'importer_fe_CHN', 'importer_fe_COL', 'importer_fe_DZA', 'importer_fe_EGY', 'importer_fe_GHA', 'importer_fe_IDN', 'importer_fe_IRN', 'importer_fe_ISR', 'importer_fe_KEN', 'importer_fe_KOR', 'importer_fe_KWT', 'importer_fe_LBY', 'importer_fe_MAR', 'importer_fe_NGA', 'importer_fe_NLD', 'importer_fe_PAK', 'importer_fe_SAU', 'importer_fe_SGP', 'importer_fe_THA', 'importer_fe_TUN', 'importer_fe_TWN', 'importer_fe_URY', 'importer_fe_VEN', 'importer_fe_ZAF']\n\n\nEstimation completed at 08:09 AM  on Oct 16, 2018\n\n\n\n\n\nThe results are stored in a collection (called dictionary in Python) with each sector having its own set of results. If no sectors were supplied or used, there would be only one set of results in the dictionary, labeled 'all'.\n\n\nA simple table with regression results can be produced with the following command: \n\n\ngme_model\n.\nformat_regression_table\n(\nformat\n \n=\n \n\"txt\"\n)\n\n\n\nwhich produces the regression results:\n\n                             Variable                all\n\n\na_agree_pta                 agree_pta           0.338***\n\n\na_agree_pta_se                                   (0.088)\n\n\na_common_language     common_language              0.063\n\n\na_common_language_se                             (0.071)\n\n\na_contiguity               contiguity           0.211***\n\n\na_contiguity_se                                  (0.085)\n\n\na_exporter_fe_ARG     exporter_fe_ARG             -0.444\n\n\na_exporter_fe_ARG_se                             (0.365)\n\n\na_exporter_fe_AUS     exporter_fe_AUS              0.619\n\n\na_exporter_fe_AUS_se                             (0.500)\n\n\n                               ...                ...\n\n\na_importer_fe_USA     importer_fe_USA          30.791***\n\n\na_importer_fe_USA_se                             (0.562)\n\n\na_log_distance           log_distance          -0.784***\n\n\na_log_distance_se                                (0.051)\n\n\nb_aic                             AIC  1806014725995.581\n\n\nb_bic                             BIC  1806014667986.696\n\n\nb_llf                      Likelihood   -903007362899.79\n\n\nb_nobs                           Obs.               2040",
            "title": "Getting started"
        },
        {
            "location": "/getting_started/#getting-started",
            "text": "",
            "title": "Getting Started"
        },
        {
            "location": "/getting_started/#preparing-the-software",
            "text": "",
            "title": "Preparing the Software"
        },
        {
            "location": "/getting_started/#dependencies",
            "text": "The GME package requires pandas, statsmodels, patsy, and scipy packages. If not already present on your system, they will be automatically installed when installing GME.",
            "title": "Dependencies"
        },
        {
            "location": "/getting_started/#installation",
            "text": "Download and install the GME package.  pip   install   gme",
            "title": "Installation"
        },
        {
            "location": "/getting_started/#a-basic-example-run-ppml-estimation",
            "text": "",
            "title": "A Basic Example: Run PPML estimation"
        },
        {
            "location": "/getting_started/#step-1-import-the-needed-packages",
            "text": "import   gme   as   gme  import   pandas   as   pd",
            "title": "Step 1. Import the needed packages"
        },
        {
            "location": "/getting_started/#step-2-create-estimationdata",
            "text": "The GME package is built upon a specialized data object called EstimationData. EstimationData contains data in a  Pandas DataDrame  as well as a collection of additional information and tools that are useful for gravity modeling, such as    A log of the history of the data, such as the location of the file it was read from and modifications made to it,  Metadata, such as names of the columns containing importer, exporter, and year information, so that they need not be continuously supplied,  Several tools for producing summary statistics or other types of commonly sought descriptive information.   Begin by loading example trade data.  The dataset used in the following code is  available for download  or can be accessed directly with python and pandas, as shown below.  sample_data   =   pd . read_csv ( \n     'https://www.usitc.gov/data/gravity/example_trade_and_grav_data_small.csv' )  print ( sample_data . head ())  \nThe first command above reads the data file into memory while the second shows the column names and first 5 lines of the data file.   importer exporter  year   trade_value  agree_pta  common_language  \\  0      AUS      BRA  1989  3.035469e+08        0.0              1.0     1      AUS      CAN  1989  8.769946e+08        0.0              1.0     2      AUS      CHE  1989  4.005245e+08        0.0              1.0     3      AUS      DEU  1989  2.468977e+09        0.0              0.0     4      AUS      DNK  1989  1.763072e+08        0.0              1.0        contiguity  log_distance    0         0.0      9.553332    1         0.0      9.637676    2         0.0      9.687557    3         0.0      9.675007    4         0.0      9.657311    Next, create an instance of the EstimationData object using the sample data. To create an EstimationData instance (called gme_data in the example below), you need to supply a Pandas DataFrame and identifiers for certain key columns, such as the trade flows, importer/exporter, year, and sector (if applicable).  gme_data   =   gme . EstimationData ( data_frame   =   sample_data , \n                               imp_var_name   =   'importer' , \n                               exp_var_name   =   'exporter' , \n                               trade_var_name   =   'trade_value' , \n                               year_var_name   =   'year' )  print ( gme_data )  \nThe print command above produces basic summary statistics, contained in a printable representation of the EstimationData class:  number of countries: 62   number of exporters: 62   number of importers: 62   number of years: 27   number of sectors: not_applicable   dimensions: (98612, 8)",
            "title": "Step 2. Create EstimationData"
        },
        {
            "location": "/getting_started/#step-3-create-an-estimationmodel",
            "text": "After creating an EstimationData object, you need to create an EstimationModel object, which will be used to produce gravity estimates.  To create an EstimationModel instance (called gme_model in the example below), you need to supply an EstimationData object and a specification.  gme_model   =   gme . EstimationModel ( estimation_data   =   gme_data , \n                                 lhs_var   =   'trade_value' , \n                                 rhs_var   =   [ 'log_distance' , 'agree_pta' , 'common_language' , 'contiguity' ], \n                                 fixed_effects   =   [ 'importer' ,   'exporter' ], \n                                 keep_years   =   [ 2015 ])   The initialization of EstimationModel establishes a reference to the EstimationData object rather than a copy of the data.",
            "title": "Step 3. Create an EstimationModel"
        },
        {
            "location": "/getting_started/#step-4-estimate-the-model",
            "text": "What is a method? A method is a function that is connected only to a particular object.  Click here to see the relevant Python documentation. Once the EstimationModel is defined, it can be estimated by applying the method .estimate()  gme_model . estimate ()   The code provides some information while it is running:  select specification variables: ['log_distance', 'agree_pta', 'common_language', 'contiguity', 'trade_value', 'importer', 'exporter', 'year'], Observations excluded by user: {'rows': 0, 'columns': 0}  drop_intratrade: no, Observations excluded by user: {'rows': 0, 'columns': 0}  drop_imp: none, Observations excluded by user: {'rows': 0, 'columns': 0}  drop_exp: none, Observations excluded by user: {'rows': 0, 'columns': 0}  keep_imp: all available, Observations excluded by user: {'rows': 0, 'columns': 0}  keep_exp: all available, Observations excluded by user: {'rows': 0, 'columns': 0}  drop_years: none, Observations excluded by user: {'rows': 0, 'columns': 0}  keep_years: [2015], Observations excluded by user: {'rows': 94952, 'columns': 0}  drop_missing: yes, Observations excluded by user: {'rows': 0, 'columns': 0}  Estimation began at 08:09 AM  on Oct 16, 2018  Omitted Columns: ['importer_fe_ARG', 'importer_fe_AUT', 'importer_fe_BEL', 'importer_fe_CHN', 'importer_fe_COL', 'importer_fe_DZA', 'importer_fe_EGY', 'importer_fe_GHA', 'importer_fe_IDN', 'importer_fe_IRN', 'importer_fe_ISR', 'importer_fe_KEN', 'importer_fe_KOR', 'importer_fe_KWT', 'importer_fe_LBY', 'importer_fe_MAR', 'importer_fe_NGA', 'importer_fe_NLD', 'importer_fe_PAK', 'importer_fe_SAU', 'importer_fe_SGP', 'importer_fe_THA', 'importer_fe_TUN', 'importer_fe_TWN', 'importer_fe_URY', 'importer_fe_VEN', 'importer_fe_ZAF']  Estimation completed at 08:09 AM  on Oct 16, 2018   The results are stored in a collection (called dictionary in Python) with each sector having its own set of results. If no sectors were supplied or used, there would be only one set of results in the dictionary, labeled 'all'.  A simple table with regression results can be produced with the following command:   gme_model . format_regression_table ( format   =   \"txt\" )  \nwhich produces the regression results:                              Variable                all  a_agree_pta                 agree_pta           0.338***  a_agree_pta_se                                   (0.088)  a_common_language     common_language              0.063  a_common_language_se                             (0.071)  a_contiguity               contiguity           0.211***  a_contiguity_se                                  (0.085)  a_exporter_fe_ARG     exporter_fe_ARG             -0.444  a_exporter_fe_ARG_se                             (0.365)  a_exporter_fe_AUS     exporter_fe_AUS              0.619  a_exporter_fe_AUS_se                             (0.500)                                 ...                ...  a_importer_fe_USA     importer_fe_USA          30.791***  a_importer_fe_USA_se                             (0.562)  a_log_distance           log_distance          -0.784***  a_log_distance_se                                (0.051)  b_aic                             AIC  1806014725995.581  b_bic                             BIC  1806014667986.696  b_llf                      Likelihood   -903007362899.79  b_nobs                           Obs.               2040",
            "title": "Step 4. Estimate the model"
        },
        {
            "location": "/estimation_tutorial/",
            "text": "Estimating a Gravity Model\n\n\nThis tutorial demonstrates a basic gravity analysis including loading data, constructing some summary statistics, estimating a model, and outputting the results in several possible formats. For more information, see the list of commands and API reference in this documentation.\n\n\nLoad Data\n\n\nThe gme package uses a special object, called gme.EstimationData to store data. EstimationData includes a \nPandas.DataFrame\n containing data (trade + gravity + etc.) for estimation as well as additional information about that data and methods that can be used to summarize and/or manipulate the data.  This tutorial will demonstrate some of these features.\n\n\nFirst, we must begin by creating a gme.EstimationData.  Doing so requires the inputting of a Pandas.DataFrame and several pieces of \"meta-data\" that describe the data. Start by loading a dataset using the \nread_csv()\n function from pandas.  In the sample code below, we will read a dataset directly from the internet, but you could just as easily read the same file from your hard drive. \n\n\n>>>\n \nimport\n \ngme\n \nas\n \ngme\n\n\n>>>\n \nimport\n \npandas\n \nas\n \npd\n\n\n\n>>>\n \ngravity_data\n \n=\n \npd\n.\nread_csv\n(\n'https://www.usitc.gov/data/gravity/example_trade_and_grav_data_small.csv'\n)\n\n\n\n>>>\n \ngravity_data\n.\nhead\n()\n\n  \nimporter\n \nexporter\n  \nyear\n   \ntrade_value\n  \nagree_pta\n  \ncommon_language\n  \\\n\n0\n      \nAUS\n      \nBRA\n  \n1989\n  \n3.035469e+08\n        \n0.0\n              \n1.0\n   \n\n1\n      \nAUS\n      \nCAN\n  \n1989\n  \n8.769946e+08\n        \n0.0\n              \n1.0\n   \n\n2\n      \nAUS\n      \nCHE\n  \n1989\n  \n4.005245e+08\n        \n0.0\n              \n1.0\n   \n\n3\n      \nAUS\n      \nDEU\n  \n1989\n  \n2.468977e+09\n        \n0.0\n              \n0.0\n   \n\n4\n      \nAUS\n      \nDNK\n  \n1989\n  \n1.763072e+08\n        \n0.0\n              \n1.0\n \n\n   \ncontiguity\n  \nlog_distance\n  \n\n0\n         \n0.0\n      \n9.553332\n  \n\n1\n         \n0.0\n      \n9.637676\n  \n\n2\n         \n0.0\n      \n9.687557\n  \n\n3\n         \n0.0\n      \n9.675007\n  \n\n4\n         \n0.0\n      \n9.657311\n \n\n\n\n# Next, we use the loaded data to create an EstimationData instance called gme_data\n\n\n>>>\n \ngme_data\n \n=\n \ngme\n.\nEstimationData\n(\ndata_frame\n=\ngravity_data\n,\n\n                              \nimp_var_name\n=\n'importer'\n,\n\n                              \nexp_var_name\n=\n'exporter'\n,\n\n                              \ntrade_var_name\n=\n'trade_value'\n,\n\n                              \nyear_var_name\n=\n'year'\n,\n\n                              \nnotes\n=\n'Downloaded from https://www.usitc.gov/data/gravity/example_trade_and_grav_data_small.csv'\n)\n\n\n\n\n\nIn creating an instance of the EstimationData object, the user is asked to supply a Pandas.DataFrame, which we a loaded in the previous lines, and several types of descriptive arguments. These arguments (\nimp_var_name\n, \nexp_var_name\n, \ntrade_var_name\n, and \nyear_var_name\n) specify the columns in the supplied DataFrame corresponding to particular types of information that will likely be present in any gravity analysis (the column containing the importer ID, exporter ID, trade values, and year, respectively). These \"meta-data\" fields can be useful as they prevent users from having to re-enter these same basic characteristics of the data at later points and permit the automatic construction of certain types of summary information. Finally, an optional \nnote\n is supplied to the EstimationData. The EstimationData object has a attribute that stores a list user-supplied strings for later reference. In this case, we have supplied a note indicating from where the data originated.\n\n\nWorking with EstimationData\n\n\nIn addition to providing an object class that communicates conveniently with the gme.EstimationModel (see below), the EstimationData provides a collection of data summary and manipulation tools.  For example, simply calling (or printing) the object, returns a summary of the scope of the data:\n\n\n>>>\n \ngme_data\n\n\nnumber\n \nof\n \ncountries\n:\n \n62\n \n\nnumber\n \nof\n \nexporters\n:\n \n62\n \n\nnumber\n \nof\n \nimporters\n:\n \n62\n \n\nnumber\n \nof\n \nyears\n:\n \n27\n \n\nnumber\n \nof\n \nsectors\n:\n \nnot_applicable\n \n\ndimensions\n:\n \n(\n98612\n,\n \n8\n)\n\n\n\nAs can be seen from the console return, the dataset we are using covers 62 importers and exporters, 27 years, and contains 98,612 rows and 8 columns. Because this particular dataset does not have multiple sectors, that field is marked as 'not applicable'.\n1\n \n\n\nOther summary information can be reported in the following ways:\n\n# Return the number of importers in the dataset.\n\n\n>>>\n \ngme_data\n.\nnumber_of_importers\n\n\n62\n\n\n\n# Return a list of the column names\n\n\n>>>\n \ngme_data\n.\ncolumns\n\n\n[\n'importer'\n,\n \n'exporter'\n,\n \n'year'\n,\n \n'trade_value'\n,\n \n'agree_pta'\n,\n \n'common_language'\n,\n \n\n'contiguity'\n,\n \n'log_distance'\n]\n\n\n\n# Return a list of years in the dataset\n\n\n>>>\n \ngme_data\n.\nyear_list\n()\n \n\n[\n1989\n,\n \n1990\n,\n \n1991\n,\n \n1992\n,\n \n1993\n,\n \n1994\n,\n \n1995\n,\n \n1996\n,\n \n1997\n,\n \n1998\n,\n \n1999\n,\n \n2000\n,\n \n2001\n,\n \n2002\n,\n \n\n2003\n,\n \n2004\n,\n \n2005\n,\n \n2006\n,\n \n2007\n,\n \n2008\n,\n \n2009\n,\n \n2010\n,\n \n2011\n,\n \n2012\n,\n \n2013\n,\n \n2014\n,\n \n2015\n]\n\n\n\n# Return a dictionary containing a list of countries in the dataset for each year.\n\n\n>>>\n \ncountry_list\n \n=\n \ngme_data\n.\ncountries_each_year\n()\n\n\n>>>\n \ncountry_list\n[\n1989\n]\n\n\n[\n'IRN'\n,\n \n'BOL'\n,\n \n'TUR'\n,\n \n'ARG'\n,\n \n'CHL'\n,\n \n'HUN'\n,\n \n'KEN'\n,\n \n'VEN'\n,\n \n'ZAF'\n,\n \n'URY'\n,\n \n'BRA'\n,\n \n'DZA'\n,\n\n \n'PER'\n,\n \n'IRL'\n,\n \n'DNK'\n,\n \n'GHA'\n,\n \n'KOR'\n,\n \n'PAK'\n,\n \n'COL'\n,\n \n'IND'\n,\n \n'ISL'\n,\n \n'ISR'\n,\n \n'ESP'\n,\n \n'ITA'\n,\n\n \n'NLD'\n,\n \n'NGA'\n,\n \n'AUS'\n,\n \n'SWE'\n,\n \n'PRY'\n,\n \n'GBR'\n,\n \n'IDN'\n,\n \n'HKG'\n,\n \n'NOR'\n,\n \n'TUN'\n,\n \n'EGY'\n,\n \n'KWT'\n,\n \n \n'DEU'\n,\n \n'CHE'\n,\n \n'MYS'\n,\n \n'NZL'\n,\n \n'LBY'\n,\n \n'USA'\n,\n \n'SDN'\n,\n \n'CHN'\n,\n \n'GRC'\n,\n \n'MEX'\n,\n \n'CAN'\n,\n \n'PRT'\n,\n \n \n'SAU'\n,\n \n'POL'\n,\n \n'PHL'\n,\n \n'THA'\n,\n \n'FRA'\n,\n \n'JPN'\n,\n \n'MAR'\n,\n \n'AUT'\n,\n \n'FIN'\n,\n \n'SGP'\n,\n \n'ECU'\n]\n\n\n\n# Additionally, many of the descriptive methods from Pandas.DataFrames have been inherited:\n\n\n>>>\n \ngme_data\n.\ndtypes\n()\n\n\nimporter\n            \nobject\n\n\nexporter\n            \nobject\n\n\nyear\n                 \nint64\n\n\ntrade_value\n        \nfloat64\n\n\nagree_pta\n          \nfloat64\n\n\ncommon_language\n    \nfloat64\n\n\ncontiguity\n         \nfloat64\n\n\nlog_distance\n       \nfloat64\n\n\ndtype\n:\n \nobject\n\n\n\n>>>\n \ngme_data\n.\ninfo\n()\n\n\n<\nclass\n \n'\npandas\n.\ncore\n.\nframe\n.\nDataFrame\n'>\n\n\nRangeIndex\n:\n \n98612\n \nentries\n,\n \n0\n \nto\n \n98611\n\n\nData\n \ncolumns\n \n(\ntotal\n \n8\n \ncolumns\n):\n\n\nimporter\n           \n98612\n \nnon\n-\nnull\n \nobject\n\n\nexporter\n           \n98612\n \nnon\n-\nnull\n \nobject\n\n\nyear\n               \n98612\n \nnon\n-\nnull\n \nint64\n\n\ntrade_value\n        \n98612\n \nnon\n-\nnull\n \nfloat64\n\n\nagree_pta\n          \n97676\n \nnon\n-\nnull\n \nfloat64\n\n\ncommon_language\n    \n97676\n \nnon\n-\nnull\n \nfloat64\n\n\ncontiguity\n         \n97676\n \nnon\n-\nnull\n \nfloat64\n\n\nlog_distance\n       \n97676\n \nnon\n-\nnull\n \nfloat64\n\n\ndtypes\n:\n \nfloat64\n(\n5\n),\n \nint64\n(\n1\n),\n \nobject\n(\n2\n)\n\n\nmemory\n \nusage\n:\n \n6.0\n+\n \nMB\n\n\n\n>>>\n \ngme_data\n.\ndescribe\n()\n\n               \nyear\n   \ntrade_value\n     \nagree_pta\n  \ncommon_language\n  \\\n\ncount\n  \n98612.000000\n  \n9.861200e+04\n  \n97676.000000\n     \n97676.000000\n   \n\nmean\n    \n2002.210441\n  \n1.856316e+09\n      \n0.381547\n         \n0.380646\n   \n\nstd\n        \n7.713050\n  \n1.004735e+10\n      \n0.485769\n         \n0.485548\n   \n\nmin\n     \n1989.000000\n  \n0.000000e+00\n      \n0.000000\n         \n0.000000\n   \n\n25\n%\n     \n1996.000000\n  \n1.084703e+06\n      \n0.000000\n         \n0.000000\n   \n\n50\n%\n     \n2002.000000\n  \n6.597395e+07\n      \n0.000000\n         \n0.000000\n   \n\n75\n%\n     \n2009.000000\n  \n6.125036e+08\n      \n1.000000\n         \n1.000000\n   \n\nmax\n     \n2015.000000\n  \n4.977686e+11\n      \n1.000000\n         \n1.000000\n   \n\n         \ncontiguity\n  \nlog_distance\n  \n\ncount\n  \n97676.000000\n  \n97676.000000\n  \n\nmean\n       \n0.034051\n      \n8.722631\n  \n\nstd\n        \n0.181362\n      \n0.818818\n  \n\nmin\n        \n0.000000\n      \n5.061335\n  \n\n25\n%\n        \n0.000000\n      \n8.222970\n  \n\n50\n%\n        \n0.000000\n      \n9.012502\n  \n\n75\n%\n        \n0.000000\n      \n9.303026\n  \n\nmax\n        \n1.000000\n      \n9.890765\n  \n\n\n\nAdditionally, the EstimationData object retains the full ability to work with the supplied DataFrame.  The DataFrame can be easily accessed by referring to its attribute in EstimationData.\n\n# Return the column of trade_values\n\n\n>>>\n \ngme_data\n.\ndata_frame\n[\n'trade_value'\n]\n\n\n0\n        \n3.035469e+08\n\n\n1\n        \n8.769946e+08\n\n\n2\n        \n4.005245e+08\n\n             \n...\n     \n\n98609\n    \n0.000000e+00\n\n\n98610\n    \n0.000000e+00\n\n\n98611\n    \n0.000000e+00\n\n\nName\n:\n \ntrade_value\n,\n \nLength\n:\n \n98612\n,\n \ndtype\n:\n \nfloat64\n\n\n\n\nFinally, the EstimationData object features a tool for easy aggregation and custom summary information. Additionally, because the method used for this process returns a DataFrame, the aggregated information can itself be used for many other applications, including the creation of a new EstimationData object.\n\n\n\n\nNote\n\n\nKnowing when to end a command with \n( )\n:\n When first learning python, it can be confusing trying to determine when a command applied to an object should be followed by parentheses. In the preceding code example, you will see instances of both: \ngme_data.columns\n and \ngme_data.year_list( )\n, for example.  Knowing which format to use is largely a matter of becoming familiar with the functions you are using.  However, there is a logic to it.  Each time a command is applied to an object (i.e. using the syntax \nobject.command\n), you are calling either an \nattribute\n of the object or a \nmethod\n on the object.  An attribute is a piece of information that has already been created and included in the object whereas a method is effectively a function that can be run on the object.  A method will be called with two parentheses because they will often accept additional arguments. For example, this is the case with the DataFrame method \nhead( )\n, which can accept a user-provided number of rows.  However, you will often find that you do not need to supply additional arguments to a method, in which case you leave the parentheses empty.  An attribute, by comparison, does not feature \n( )\n because there is no need or ability to provide additional input because the contents of that attribute have already been computed. As mentioned before, knowing whether a command is an attribute or a method, however, simply requires familiarity with the object.  \n\n\n\n\nCreating and estimating a model\n\n\nOnce a EstimationData has been created, estimating a gravity model using the data is fairly straightforward.  There are two basic step for estimation: (1) define a model and (2) estimate the model.\n\n\nDefining the model amounts to creating another object called \nEstimationModel\n.  Like the EstimationData, EstimationModel is meant to standardize and simplify the steps typically taken to specify and estimate a gravity model.  While the EstimationData is meant to be an object that is created once for each study, many EstimationModels will likely be defined and redefined as you test different specifications. Thus, the arguments and attributes of the EstimationModel reflect the different types of modifications you may want to make as you select your preferred specification. \n\n\nAs with the EstimationData, the EstimationModel is largely a dataset, with added information that define the characteristics of the particular model. The following examples depict several model specifications, each demonstrating different types of model aspects that can be specified.\n\n\n# A simple case in which 'trade_value' is dependent on 'log_distance', 'agree_pta', etc.\n\n\n>>>\n \nmodel_baseline\n \n=\n \ngme\n.\nEstimationModel\n(\nestimation_data\n \n=\n \ngme_data\n,\n\n                                         \nlhs_var\n \n=\n \n'trade_value'\n,\n\n                                         \nrhs_var\n \n=\n \n[\n'log_distance'\n,\n\n                                                    \n'agree_pta'\n,\n \n                                                    \n'common_language'\n,\n\n                                                    \n'contiguity'\n])\n\n\n\n# A specification that will generate and include importer-year and exporter-year\n\n\n# fixed effects                                                    \n\n\n>>>\n \nfixed_effects_model\n  \n=\n \ngme\n.\nEstimationModel\n(\nestimation_data\n \n=\n \ngme_data\n,\n\n                                 \nlhs_var\n \n=\n \n'trade_value'\n,\n\n                                 \nrhs_var\n \n=\n \n[\n'log_distance'\n,\n\n                                            \n'agree_pta'\n,\n \n                                            \n'common_language'\n,\n\n                                            \n'contiguity'\n],\n\n                                 \nfixed_effects\n=\n[[\n'importer'\n,\n'year'\n],\n\n                                                \n[\n'exporter'\n,\n'year'\n]])\n\n\n\n# A specification that uses a subset of the data. The United States ('USA') will be omitted\n\n\n# and only the years 2013--2015 will be included.\n\n\n>>>\n \ndata_subset_model\n \n=\n \ngme\n.\nEstimationModel\n(\nestimation_data\n \n=\n \ngme_data\n,\n\n                                            \nlhs_var\n \n=\n \n'trade_value'\n,\n\n                                            \nrhs_var\n \n=\n \n[\n'log_distance'\n,\n\n                                                       \n'agree_pta'\n,\n \n                                                       \n'common_language'\n,\n\n                                                       \n'contiguity'\n],\n\n                                            \ndrop_imp_exp\n=\n[\n'USA'\n],\n\n                                            \nkeep_years\n=\n[\n2015\n,\n \n2014\n,\n \n2013\n])\n                                                  \n\n\nWhen specifying a model, there are several key types of attributes that can be included:\n\n\n\n\nModel Variables\n: The variables to be included are specified using the arguments \nlhs_vars\n and \nrhs_vars\n, which denote the left-hand-side dependent variable and right-hand-side independent variables, respectively.\n\n\nFixed Effects\n: The model, at the point at which it is estimated, will construct fixed effects if any are specified by \nfixed_effects\n.  These can be either single variables (e.g. ['importer']), or interacted variables (e.g. [['importer', 'year']]). For example, entering [ 'importer', ['exporter', 'year']] would yield a set of importer fixed effects and a set of exporter-year fixed effects.  \n\n\nData Subsets\n: Subsets of the data to use for estimation can be specified in a variety of ways. The arguments \nkeep_years\n and \ndrop_years\n can be used to select only a subset of years to include. Similarly the \nkeep_imp\n, \nkeep_exp\n, and \nkeep_imp_exp\n arguments, and their corresponding \ndrop_...\n options can do the same for importers and/or exporters. \n\n\n\n\nOnce a model has been defined, running a PPML estimation according to the supplied specification is quite straightforward. It only requires the application of a single method of the EstimationModel: \n.estimate()\n.  No further inputs are required.\n\n\n# Define a new, fixed effects model using only a subset of years (to reduce the computation time)\n\n\n>>>\n \nfixed_effects_model_2\n  \n=\n \ngme\n.\nEstimationModel\n(\nestimation_data\n \n=\n \ngme_data\n,\n\n                                                 \nlhs_var\n \n=\n \n'trade_value'\n,\n\n                                                 \nrhs_var\n \n=\n \n[\n'log_distance'\n,\n\n                                                            \n'agree_pta'\n,\n \n                                                            \n'common_language'\n,\n\n                                                            \n'contiguity'\n],\n\n                                                 \nfixed_effects\n=\n[[\n'importer'\n,\n'year'\n],\n\n                                                                \n[\n'exporter'\n,\n'year'\n]],\n\n                                                 \nkeep_years\n \n=\n \n[\n2013\n,\n2014\n,\n2015\n])\n\n\n\n# Conduct a PPML estimation of the fixed effects model.\n\n\nestimates\n \n=\n \nfixed_effects_model_2\n.\nestimate\n()\n\n\nselect\n \nspecification\n \nvariables\n:\n \n[\n'log_distance'\n,\n \n'agree_pta'\n,\n \n'common_language'\n,\n \n'contiguity'\n,\n \n'trade_value'\n,\n \n'importer'\n,\n \n'exporter'\n,\n \n'year'\n],\n \nObservations\n \nexcluded\n \nby\n \nuser\n:\n \n{\n'rows'\n:\n \n0\n,\n \n'columns'\n:\n \n0\n}\n\n\ndrop_intratrade\n:\n \nno\n,\n \nObservations\n \nexcluded\n \nby\n \nuser\n:\n \n{\n'rows'\n:\n \n0\n,\n \n'columns'\n:\n \n0\n}\n\n\ndrop_imp\n:\n \nnone\n,\n \nObservations\n \nexcluded\n \nby\n \nuser\n:\n \n{\n'rows'\n:\n \n0\n,\n \n'columns'\n:\n \n0\n}\n\n\ndrop_exp\n:\n \nnone\n,\n \nObservations\n \nexcluded\n \nby\n \nuser\n:\n \n{\n'rows'\n:\n \n0\n,\n \n'columns'\n:\n \n0\n}\n\n\nkeep_imp\n:\n \nall\n \navailable\n,\n \nObservations\n \nexcluded\n \nby\n \nuser\n:\n \n{\n'rows'\n:\n \n0\n,\n \n'columns'\n:\n \n0\n}\n\n\nkeep_exp\n:\n \nall\n \navailable\n,\n \nObservations\n \nexcluded\n \nby\n \nuser\n:\n \n{\n'rows'\n:\n \n0\n,\n \n'columns'\n:\n \n0\n}\n\n\ndrop_years\n:\n \nnone\n,\n \nObservations\n \nexcluded\n \nby\n \nuser\n:\n \n{\n'rows'\n:\n \n0\n,\n \n'columns'\n:\n \n0\n}\n\n\nkeep_years\n:\n \n[\n2013\n,\n \n2014\n,\n \n2015\n],\n \nObservations\n \nexcluded\n \nby\n \nuser\n:\n \n{\n'rows'\n:\n \n87632\n,\n \n'columns'\n:\n \n0\n}\n\n\ndrop_missing\n:\n \nyes\n,\n \nObservations\n \nexcluded\n \nby\n \nuser\n:\n \n{\n'rows'\n:\n \n0\n,\n \n'columns'\n:\n \n0\n}\n\n\nEstimation\n \nbegan\n \nat\n \n08\n:\n58\n \nAM\n  \non\n \nJun\n \n19\n,\n \n2018\n\n\nEstimation\n \ncompleted\n \nat\n \n08\n:\n58\n \nAM\n  \non\n \nJun\n \n19\n,\n \n2018\n\n\n\n The results (\nestimates\n) are stored as a dictionary with each entry in the dictionary corresponding to a single estimation.\n2\n  The storing of the results in this way is primarily to facilitate the \nsector_by_sector\n, which separately estimates a model for each product/industry/sector, and returns a set of estimation results for each.  In the case in which multiple sectors are not considered, as in the examples considered here, the results dictionary contains a single entry with the key 'all'.  \n\n\nViewing, formatting, and outputting the results\n\n\nThe first step to viewing and working with the regression estimates is unpacking them from the dictionary in which they have been stored. A dictionary is an object in which each item stored in the dictionary is associated with a key.  That key can be used to return its associated item. In the above example, \nestimates\n is a dictionary in which each item is an object of results. In our example there is only one object because only one regression was run. In cases in which multiple regressions are run because multiple sectors are estimated separately, the dictionary would contain multiple results, each keyed with the name of the respective sector. \n\n# Return a list of keys in the object\n\n\n>>>\n \nestimates\n.\nkeys\n()\n\n\ndict_keys\n([\n'all'\n])\n\n\n\n# Return the result object and save it to a new variable for convenience \n\n\n>>>\n \nresults\n \n=\n \nestimates\n[\n'all'\n]\n\n\n\n\nThe estimation uses tools from the \nstatsmodels\n package so that the results inherit all of the features of the \nstatsmodels\n GLM results object.\n3\n  This means that the object contains a plethora of fields reflecting things like coefficient estimates, standard errors, p-values, AIC/BIC, etc.  Similarly, there is a useful method associated with the object that can be used for creating summary tables.\n\n\n# print a summary of the results\n\n\n>>>\n \nresults\n.\nsummary\n()\n\n\n<\nclass\n \n'\nstatsmodels\n.\niolib\n.\nsummary\n.\nSummary\n'>\n\n                 \nGeneralized\n \nLinear\n \nModel\n \nRegression\n \nResults\n                  \n\n==============================================================================\n\n\nDep\n.\n \nVariable\n:\n            \ntrade_value\n   \nNo\n.\n \nObservations\n:\n                 \n8700\n\n\nModel\n:\n                            \nGLM\n   \nDf\n \nResiduals\n:\n                     \n8371\n\n\nModel\n \nFamily\n:\n                 \nPoisson\n   \nDf\n \nModel\n:\n                          \n328\n\n\nLink\n \nFunction\n:\n                    \nlog\n   \nScale\n:\n                             \n1.0\n\n\nMethod\n:\n                          \nIRLS\n   \nLog\n-\nLikelihood\n:\n            \n-\n4.8282e+12\n\n\nDate\n:\n                \nWed\n,\n \n20\n \nJun\n \n2018\n   \nDeviance\n:\n                   \n9.6565e+12\n\n\nTime\n:\n                        \n13\n:\n36\n:\n10\n   \nPearson\n \nchi2\n:\n                 \n1.22e+13\n\n\nNo\n.\n \nIterations\n:\n                    \n10\n                                         \n\n============================================================================================\n\n                               \ncoef\n    \nstd\n \nerr\n          \nz\n      \nP\n>|\nz\n|\n      \n[\n0.025\n      \n0.975\n]\n\n\n--------------------------------------------------------------------------------------------\n\n\nlog_distance\n                \n-\n0.7398\n      \n0.024\n    \n-\n30.982\n      \n0.000\n      \n-\n0.787\n      \n-\n0.693\n\n\nagree_pta\n                    \n0.3342\n      \n0.043\n      \n7.824\n      \n0.000\n       \n0.250\n       \n0.418\n\n\ncommon_language\n              \n0.1288\n      \n0.039\n      \n3.270\n      \n0.001\n       \n0.052\n       \n0.206\n\n\ncontiguity\n                   \n0.2552\n      \n0.047\n      \n5.423\n      \n0.000\n       \n0.163\n       \n0.347\n\n\nimporter_year_fe_ARG2013\n    \n26.9804\n      \n0.361\n     \n74.690\n      \n0.000\n      \n26.272\n      \n27.688\n\n\nimporter_year_fe_ARG2014\n    \n26.8032\n      \n0.344\n     \n77.840\n      \n0.000\n      \n26.128\n      \n27.478\n\n\nimporter_year_fe_AUS2013\n    \n28.1690\n      \n0.315\n     \n89.455\n      \n0.000\n      \n27.552\n      \n28.786\n\n\n...\n \n(\ntruncated\n \nfor\n \nthis\n \ntutorial\n)\n\n\n============================================================================================\n\n\n\n\n# Extract the estimated parameter values (returned as a Pandas.Series)\n\n\n>>>\n \ncoefficients\n \n=\n \nresults\n.\nparams\n\n\n>>>\n \ncoefficients\n.\nhead\n()\n\n\nlog_distance\n                \n-\n0.739840\n\n\nagree_pta\n                    \n0.334219\n\n\ncommon_language\n              \n0.128770\n\n\ncontiguity\n                   \n0.255161\n\n\nimporter_year_fe_ARG2013\n    \n26.980367\n\n\ndtype\n:\n \nfloat64\n\n\n\n# Extract the standard errors\n\n\n>>>\n \nresults\n.\nbse\n\n\nlog_distance\n                \n0.023879\n\n\nagree_pta\n                   \n0.042720\n\n                              \n...\n   \n\nexporter_year_fe_VEN2015\n    \n0.346733\n\n\nLength\n:\n \n329\n,\n \ndtype\n:\n \nfloat64\n\n\n\n# Extract the p-values\n\n\n>>>\n \nresults\n.\npvalues\n\n\nlog_distance\n                \n9.318804e-211\n\n\nagree_pta\n                    \n5.134355e-15\n\n                                \n...\n      \n\nexporter_year_fe_VEN2015\n     \n5.681631e-03\n\n\nLength\n:\n \n329\n,\n \ndtype\n:\n \nfloat64\n                                \n\n\n# Return fitted values\n\n\n>>>\n \nresults\n.\nfittedvalues\n\n\n0\n       \n1.610136e+09\n\n\n1\n       \n3.044133e+08\n\n\n2\n       \n5.799368e+08\n\n            \n...\n\n\n9359\n    \n1.329831e+10\n\n\nLength\n:\n \n8700\n,\n \ndtype\n:\n \nfloat64\n\n\n\nThe estimate method also provides some diagnostic information that helps judge the quality of the regression. This information includes a listing of columns that dropped due to collinearities or an absence of trade and an indicator for over-fitting. \n\n# Return diagnostic information (a Pandas.Series or DataFrame)\n\n\n>>>\n \nfixed_effects_model_2\n.\nppml_diagnostics\n\n\nOverfit\n \nWarning\n                                                                 \nNo\n\n\nCollinearities\n                                                                 \nYes\n\n\nNumber\n \nof\n \nColumns\n \nExcluded\n                                                      \n41\n\n\nPerfectly\n \nCollinear\n \nVariables\n    \n[\nexporter_year_fe_ZAF2013\n,\n \nexporter_year_fe_ZA\n...\n\n\nZero\n \nTrade\n \nVariables\n             \n[\nimporter_year_fe_ARG2015\n,\n \nimporter_year_fe_AU\n...\n\n\nCompletion\n \nTime\n                                                       \n0.25\n \nminutes\n\n\ndtype\n:\n \nobject\n\n\n\n# Retrieve the full list of collinear columns\n\n\n>>>\n \nfixed_effects_model_2\n.\nppml_diagnostics\n[\n'Perfectly Collinear Variables'\n]\n\n\n[\n'exporter_year_fe_ZAF2013'\n,\n \n'exporter_year_fe_ZAF2014'\n,\n \n'exporter_year_fe_ZAF2015'\n]\n\n\n\n\nThe gme package also features several tools to help compile and format the results for use within python or outside of it.  These tools include one method named \ncombine_sector_results()\n for pulling all coefficients, standard errors, and p-values from from multiple sectors into a single DataFrame. The second, called \nformat_regression_tables\n, creates formatted tables for presentation that can be exported as a text file, csv file, or LaTeX file with some stylized syntax.\n\n\n\n\nTip\n\n\nLaTeX users\n: The method \nformat_regression_table\n can output a table into a csv file with some desired LaTeX syntax. This can be done by specifying \nformat = '.csv'\n and \n'latex_syntax'=True\n. This option allows users to manipulate the tables in spreadsheet software while retaining LaTeX syntax.  We recommend reading the file into the spreadsheet software as 'text data' so that it does not try to interpret the formatting of the table entries. \n\n\n\n\nThe gme package also has several ways to save the results to a file, either in full or in a space-saving slim version. See the API Reference portion of this documentation for further information. \n\n\n\n\n\n\n\n\n\n\nHad their been multiple sectors, we could have indicated so by adding the input \nsector_var_name = 'sector_column'\n in the declaration of the EstimationData.\u00a0\n\u21a9\n\n\n\n\n\n\nAdditionally, the results of the estimation are saved as a attribute of the estimation model---\nEstimationModel.results_dict\n---and can be retrieved that way as well.\u00a0\n\u21a9\n\n\n\n\n\n\nFor more details about the \nstatsmodels\n results object, see \nhttp://www.statsmodels.org/0.6.1/generated/statsmodels.genmod.generalized_linear_model.GLMResults.html\n.\u00a0\n\u21a9",
            "title": "Estimation"
        },
        {
            "location": "/estimation_tutorial/#estimating-a-gravity-model",
            "text": "This tutorial demonstrates a basic gravity analysis including loading data, constructing some summary statistics, estimating a model, and outputting the results in several possible formats. For more information, see the list of commands and API reference in this documentation.",
            "title": "Estimating a Gravity Model"
        },
        {
            "location": "/estimation_tutorial/#load-data",
            "text": "The gme package uses a special object, called gme.EstimationData to store data. EstimationData includes a  Pandas.DataFrame  containing data (trade + gravity + etc.) for estimation as well as additional information about that data and methods that can be used to summarize and/or manipulate the data.  This tutorial will demonstrate some of these features.  First, we must begin by creating a gme.EstimationData.  Doing so requires the inputting of a Pandas.DataFrame and several pieces of \"meta-data\" that describe the data. Start by loading a dataset using the  read_csv()  function from pandas.  In the sample code below, we will read a dataset directly from the internet, but you could just as easily read the same file from your hard drive.   >>>   import   gme   as   gme  >>>   import   pandas   as   pd  >>>   gravity_data   =   pd . read_csv ( 'https://www.usitc.gov/data/gravity/example_trade_and_grav_data_small.csv' )  >>>   gravity_data . head () \n   importer   exporter    year     trade_value    agree_pta    common_language   \\ 0        AUS        BRA    1989    3.035469e+08          0.0                1.0     1        AUS        CAN    1989    8.769946e+08          0.0                1.0     2        AUS        CHE    1989    4.005245e+08          0.0                1.0     3        AUS        DEU    1989    2.468977e+09          0.0                0.0     4        AUS        DNK    1989    1.763072e+08          0.0                1.0  \n\n    contiguity    log_distance    0           0.0        9.553332    1           0.0        9.637676    2           0.0        9.687557    3           0.0        9.675007    4           0.0        9.657311   # Next, we use the loaded data to create an EstimationData instance called gme_data  >>>   gme_data   =   gme . EstimationData ( data_frame = gravity_data , \n                               imp_var_name = 'importer' , \n                               exp_var_name = 'exporter' , \n                               trade_var_name = 'trade_value' , \n                               year_var_name = 'year' , \n                               notes = 'Downloaded from https://www.usitc.gov/data/gravity/example_trade_and_grav_data_small.csv' )   In creating an instance of the EstimationData object, the user is asked to supply a Pandas.DataFrame, which we a loaded in the previous lines, and several types of descriptive arguments. These arguments ( imp_var_name ,  exp_var_name ,  trade_var_name , and  year_var_name ) specify the columns in the supplied DataFrame corresponding to particular types of information that will likely be present in any gravity analysis (the column containing the importer ID, exporter ID, trade values, and year, respectively). These \"meta-data\" fields can be useful as they prevent users from having to re-enter these same basic characteristics of the data at later points and permit the automatic construction of certain types of summary information. Finally, an optional  note  is supplied to the EstimationData. The EstimationData object has a attribute that stores a list user-supplied strings for later reference. In this case, we have supplied a note indicating from where the data originated.",
            "title": "Load Data"
        },
        {
            "location": "/estimation_tutorial/#working-with-estimationdata",
            "text": "In addition to providing an object class that communicates conveniently with the gme.EstimationModel (see below), the EstimationData provides a collection of data summary and manipulation tools.  For example, simply calling (or printing) the object, returns a summary of the scope of the data:  >>>   gme_data  number   of   countries :   62   number   of   exporters :   62   number   of   importers :   62   number   of   years :   27   number   of   sectors :   not_applicable   dimensions :   ( 98612 ,   8 )  \nAs can be seen from the console return, the dataset we are using covers 62 importers and exporters, 27 years, and contains 98,612 rows and 8 columns. Because this particular dataset does not have multiple sectors, that field is marked as 'not applicable'. 1    Other summary information can be reported in the following ways: # Return the number of importers in the dataset.  >>>   gme_data . number_of_importers  62  # Return a list of the column names  >>>   gme_data . columns  [ 'importer' ,   'exporter' ,   'year' ,   'trade_value' ,   'agree_pta' ,   'common_language' ,   'contiguity' ,   'log_distance' ]  # Return a list of years in the dataset  >>>   gme_data . year_list ()   [ 1989 ,   1990 ,   1991 ,   1992 ,   1993 ,   1994 ,   1995 ,   1996 ,   1997 ,   1998 ,   1999 ,   2000 ,   2001 ,   2002 ,   2003 ,   2004 ,   2005 ,   2006 ,   2007 ,   2008 ,   2009 ,   2010 ,   2011 ,   2012 ,   2013 ,   2014 ,   2015 ]  # Return a dictionary containing a list of countries in the dataset for each year.  >>>   country_list   =   gme_data . countries_each_year ()  >>>   country_list [ 1989 ]  [ 'IRN' ,   'BOL' ,   'TUR' ,   'ARG' ,   'CHL' ,   'HUN' ,   'KEN' ,   'VEN' ,   'ZAF' ,   'URY' ,   'BRA' ,   'DZA' , \n  'PER' ,   'IRL' ,   'DNK' ,   'GHA' ,   'KOR' ,   'PAK' ,   'COL' ,   'IND' ,   'ISL' ,   'ISR' ,   'ESP' ,   'ITA' , \n  'NLD' ,   'NGA' ,   'AUS' ,   'SWE' ,   'PRY' ,   'GBR' ,   'IDN' ,   'HKG' ,   'NOR' ,   'TUN' ,   'EGY' ,   'KWT' ,  \n  'DEU' ,   'CHE' ,   'MYS' ,   'NZL' ,   'LBY' ,   'USA' ,   'SDN' ,   'CHN' ,   'GRC' ,   'MEX' ,   'CAN' ,   'PRT' ,  \n  'SAU' ,   'POL' ,   'PHL' ,   'THA' ,   'FRA' ,   'JPN' ,   'MAR' ,   'AUT' ,   'FIN' ,   'SGP' ,   'ECU' ]  # Additionally, many of the descriptive methods from Pandas.DataFrames have been inherited:  >>>   gme_data . dtypes ()  importer              object  exporter              object  year                   int64  trade_value          float64  agree_pta            float64  common_language      float64  contiguity           float64  log_distance         float64  dtype :   object  >>>   gme_data . info ()  < class   ' pandas . core . frame . DataFrame '>  RangeIndex :   98612   entries ,   0   to   98611  Data   columns   ( total   8   columns ):  importer             98612   non - null   object  exporter             98612   non - null   object  year                 98612   non - null   int64  trade_value          98612   non - null   float64  agree_pta            97676   non - null   float64  common_language      97676   non - null   float64  contiguity           97676   non - null   float64  log_distance         97676   non - null   float64  dtypes :   float64 ( 5 ),   int64 ( 1 ),   object ( 2 )  memory   usage :   6.0 +   MB  >>>   gme_data . describe () \n                year     trade_value       agree_pta    common_language   \\ count    98612.000000    9.861200e+04    97676.000000       97676.000000     mean      2002.210441    1.856316e+09        0.381547           0.380646     std          7.713050    1.004735e+10        0.485769           0.485548     min       1989.000000    0.000000e+00        0.000000           0.000000     25 %       1996.000000    1.084703e+06        0.000000           0.000000     50 %       2002.000000    6.597395e+07        0.000000           0.000000     75 %       2009.000000    6.125036e+08        1.000000           1.000000     max       2015.000000    4.977686e+11        1.000000           1.000000    \n\n          contiguity    log_distance    count    97676.000000    97676.000000    mean         0.034051        8.722631    std          0.181362        0.818818    min          0.000000        5.061335    25 %          0.000000        8.222970    50 %          0.000000        9.012502    75 %          0.000000        9.303026    max          1.000000        9.890765     Additionally, the EstimationData object retains the full ability to work with the supplied DataFrame.  The DataFrame can be easily accessed by referring to its attribute in EstimationData. # Return the column of trade_values  >>>   gme_data . data_frame [ 'trade_value' ]  0          3.035469e+08  1          8.769946e+08  2          4.005245e+08 \n              ...       98609      0.000000e+00  98610      0.000000e+00  98611      0.000000e+00  Name :   trade_value ,   Length :   98612 ,   dtype :   float64   Finally, the EstimationData object features a tool for easy aggregation and custom summary information. Additionally, because the method used for this process returns a DataFrame, the aggregated information can itself be used for many other applications, including the creation of a new EstimationData object.   Note  Knowing when to end a command with  ( ) :  When first learning python, it can be confusing trying to determine when a command applied to an object should be followed by parentheses. In the preceding code example, you will see instances of both:  gme_data.columns  and  gme_data.year_list( ) , for example.  Knowing which format to use is largely a matter of becoming familiar with the functions you are using.  However, there is a logic to it.  Each time a command is applied to an object (i.e. using the syntax  object.command ), you are calling either an  attribute  of the object or a  method  on the object.  An attribute is a piece of information that has already been created and included in the object whereas a method is effectively a function that can be run on the object.  A method will be called with two parentheses because they will often accept additional arguments. For example, this is the case with the DataFrame method  head( ) , which can accept a user-provided number of rows.  However, you will often find that you do not need to supply additional arguments to a method, in which case you leave the parentheses empty.  An attribute, by comparison, does not feature  ( )  because there is no need or ability to provide additional input because the contents of that attribute have already been computed. As mentioned before, knowing whether a command is an attribute or a method, however, simply requires familiarity with the object.",
            "title": "Working with EstimationData"
        },
        {
            "location": "/estimation_tutorial/#creating-and-estimating-a-model",
            "text": "Once a EstimationData has been created, estimating a gravity model using the data is fairly straightforward.  There are two basic step for estimation: (1) define a model and (2) estimate the model.  Defining the model amounts to creating another object called  EstimationModel .  Like the EstimationData, EstimationModel is meant to standardize and simplify the steps typically taken to specify and estimate a gravity model.  While the EstimationData is meant to be an object that is created once for each study, many EstimationModels will likely be defined and redefined as you test different specifications. Thus, the arguments and attributes of the EstimationModel reflect the different types of modifications you may want to make as you select your preferred specification.   As with the EstimationData, the EstimationModel is largely a dataset, with added information that define the characteristics of the particular model. The following examples depict several model specifications, each demonstrating different types of model aspects that can be specified.  # A simple case in which 'trade_value' is dependent on 'log_distance', 'agree_pta', etc.  >>>   model_baseline   =   gme . EstimationModel ( estimation_data   =   gme_data , \n                                          lhs_var   =   'trade_value' , \n                                          rhs_var   =   [ 'log_distance' , \n                                                     'agree_pta' ,  \n                                                     'common_language' , \n                                                     'contiguity' ])  # A specification that will generate and include importer-year and exporter-year  # fixed effects                                                      >>>   fixed_effects_model    =   gme . EstimationModel ( estimation_data   =   gme_data , \n                                  lhs_var   =   'trade_value' , \n                                  rhs_var   =   [ 'log_distance' , \n                                             'agree_pta' ,  \n                                             'common_language' , \n                                             'contiguity' ], \n                                  fixed_effects = [[ 'importer' , 'year' ], \n                                                 [ 'exporter' , 'year' ]])  # A specification that uses a subset of the data. The United States ('USA') will be omitted  # and only the years 2013--2015 will be included.  >>>   data_subset_model   =   gme . EstimationModel ( estimation_data   =   gme_data , \n                                             lhs_var   =   'trade_value' , \n                                             rhs_var   =   [ 'log_distance' , \n                                                        'agree_pta' ,  \n                                                        'common_language' , \n                                                        'contiguity' ], \n                                             drop_imp_exp = [ 'USA' ], \n                                             keep_years = [ 2015 ,   2014 ,   2013 ])                                                    \nWhen specifying a model, there are several key types of attributes that can be included:   Model Variables : The variables to be included are specified using the arguments  lhs_vars  and  rhs_vars , which denote the left-hand-side dependent variable and right-hand-side independent variables, respectively.  Fixed Effects : The model, at the point at which it is estimated, will construct fixed effects if any are specified by  fixed_effects .  These can be either single variables (e.g. ['importer']), or interacted variables (e.g. [['importer', 'year']]). For example, entering [ 'importer', ['exporter', 'year']] would yield a set of importer fixed effects and a set of exporter-year fixed effects.    Data Subsets : Subsets of the data to use for estimation can be specified in a variety of ways. The arguments  keep_years  and  drop_years  can be used to select only a subset of years to include. Similarly the  keep_imp ,  keep_exp , and  keep_imp_exp  arguments, and their corresponding  drop_...  options can do the same for importers and/or exporters.    Once a model has been defined, running a PPML estimation according to the supplied specification is quite straightforward. It only requires the application of a single method of the EstimationModel:  .estimate() .  No further inputs are required.  # Define a new, fixed effects model using only a subset of years (to reduce the computation time)  >>>   fixed_effects_model_2    =   gme . EstimationModel ( estimation_data   =   gme_data , \n                                                  lhs_var   =   'trade_value' , \n                                                  rhs_var   =   [ 'log_distance' , \n                                                             'agree_pta' ,  \n                                                             'common_language' , \n                                                             'contiguity' ], \n                                                  fixed_effects = [[ 'importer' , 'year' ], \n                                                                 [ 'exporter' , 'year' ]], \n                                                  keep_years   =   [ 2013 , 2014 , 2015 ])  # Conduct a PPML estimation of the fixed effects model.  estimates   =   fixed_effects_model_2 . estimate ()  select   specification   variables :   [ 'log_distance' ,   'agree_pta' ,   'common_language' ,   'contiguity' ,   'trade_value' ,   'importer' ,   'exporter' ,   'year' ],   Observations   excluded   by   user :   { 'rows' :   0 ,   'columns' :   0 }  drop_intratrade :   no ,   Observations   excluded   by   user :   { 'rows' :   0 ,   'columns' :   0 }  drop_imp :   none ,   Observations   excluded   by   user :   { 'rows' :   0 ,   'columns' :   0 }  drop_exp :   none ,   Observations   excluded   by   user :   { 'rows' :   0 ,   'columns' :   0 }  keep_imp :   all   available ,   Observations   excluded   by   user :   { 'rows' :   0 ,   'columns' :   0 }  keep_exp :   all   available ,   Observations   excluded   by   user :   { 'rows' :   0 ,   'columns' :   0 }  drop_years :   none ,   Observations   excluded   by   user :   { 'rows' :   0 ,   'columns' :   0 }  keep_years :   [ 2013 ,   2014 ,   2015 ],   Observations   excluded   by   user :   { 'rows' :   87632 ,   'columns' :   0 }  drop_missing :   yes ,   Observations   excluded   by   user :   { 'rows' :   0 ,   'columns' :   0 }  Estimation   began   at   08 : 58   AM    on   Jun   19 ,   2018  Estimation   completed   at   08 : 58   AM    on   Jun   19 ,   2018  \n The results ( estimates ) are stored as a dictionary with each entry in the dictionary corresponding to a single estimation. 2   The storing of the results in this way is primarily to facilitate the  sector_by_sector , which separately estimates a model for each product/industry/sector, and returns a set of estimation results for each.  In the case in which multiple sectors are not considered, as in the examples considered here, the results dictionary contains a single entry with the key 'all'.",
            "title": "Creating and estimating a model"
        },
        {
            "location": "/estimation_tutorial/#viewing-formatting-and-outputting-the-results",
            "text": "The first step to viewing and working with the regression estimates is unpacking them from the dictionary in which they have been stored. A dictionary is an object in which each item stored in the dictionary is associated with a key.  That key can be used to return its associated item. In the above example,  estimates  is a dictionary in which each item is an object of results. In our example there is only one object because only one regression was run. In cases in which multiple regressions are run because multiple sectors are estimated separately, the dictionary would contain multiple results, each keyed with the name of the respective sector.  # Return a list of keys in the object  >>>   estimates . keys ()  dict_keys ([ 'all' ])  # Return the result object and save it to a new variable for convenience   >>>   results   =   estimates [ 'all' ]   The estimation uses tools from the  statsmodels  package so that the results inherit all of the features of the  statsmodels  GLM results object. 3   This means that the object contains a plethora of fields reflecting things like coefficient estimates, standard errors, p-values, AIC/BIC, etc.  Similarly, there is a useful method associated with the object that can be used for creating summary tables.  # print a summary of the results  >>>   results . summary ()  < class   ' statsmodels . iolib . summary . Summary '> \n                  Generalized   Linear   Model   Regression   Results                    ==============================================================================  Dep .   Variable :              trade_value     No .   Observations :                   8700  Model :                              GLM     Df   Residuals :                       8371  Model   Family :                   Poisson     Df   Model :                            328  Link   Function :                      log     Scale :                               1.0  Method :                            IRLS     Log - Likelihood :              - 4.8282e+12  Date :                  Wed ,   20   Jun   2018     Deviance :                     9.6565e+12  Time :                          13 : 36 : 10     Pearson   chi2 :                   1.22e+13  No .   Iterations :                      10                                           ============================================================================================ \n                                coef      std   err            z        P >| z |        [ 0.025        0.975 ]  --------------------------------------------------------------------------------------------  log_distance                  - 0.7398        0.024      - 30.982        0.000        - 0.787        - 0.693  agree_pta                      0.3342        0.043        7.824        0.000         0.250         0.418  common_language                0.1288        0.039        3.270        0.001         0.052         0.206  contiguity                     0.2552        0.047        5.423        0.000         0.163         0.347  importer_year_fe_ARG2013      26.9804        0.361       74.690        0.000        26.272        27.688  importer_year_fe_ARG2014      26.8032        0.344       77.840        0.000        26.128        27.478  importer_year_fe_AUS2013      28.1690        0.315       89.455        0.000        27.552        28.786  ...   ( truncated   for   this   tutorial )  ============================================================================================  # Extract the estimated parameter values (returned as a Pandas.Series)  >>>   coefficients   =   results . params  >>>   coefficients . head ()  log_distance                  - 0.739840  agree_pta                      0.334219  common_language                0.128770  contiguity                     0.255161  importer_year_fe_ARG2013      26.980367  dtype :   float64  # Extract the standard errors  >>>   results . bse  log_distance                  0.023879  agree_pta                     0.042720 \n                               ...     exporter_year_fe_VEN2015      0.346733  Length :   329 ,   dtype :   float64  # Extract the p-values  >>>   results . pvalues  log_distance                  9.318804e-211  agree_pta                      5.134355e-15 \n                                 ...        exporter_year_fe_VEN2015       5.681631e-03  Length :   329 ,   dtype :   float64                                  # Return fitted values  >>>   results . fittedvalues  0         1.610136e+09  1         3.044133e+08  2         5.799368e+08 \n             ...  9359      1.329831e+10  Length :   8700 ,   dtype :   float64  \nThe estimate method also provides some diagnostic information that helps judge the quality of the regression. This information includes a listing of columns that dropped due to collinearities or an absence of trade and an indicator for over-fitting.  # Return diagnostic information (a Pandas.Series or DataFrame)  >>>   fixed_effects_model_2 . ppml_diagnostics  Overfit   Warning                                                                   No  Collinearities                                                                   Yes  Number   of   Columns   Excluded                                                        41  Perfectly   Collinear   Variables      [ exporter_year_fe_ZAF2013 ,   exporter_year_fe_ZA ...  Zero   Trade   Variables               [ importer_year_fe_ARG2015 ,   importer_year_fe_AU ...  Completion   Time                                                         0.25   minutes  dtype :   object  # Retrieve the full list of collinear columns  >>>   fixed_effects_model_2 . ppml_diagnostics [ 'Perfectly Collinear Variables' ]  [ 'exporter_year_fe_ZAF2013' ,   'exporter_year_fe_ZAF2014' ,   'exporter_year_fe_ZAF2015' ]   The gme package also features several tools to help compile and format the results for use within python or outside of it.  These tools include one method named  combine_sector_results()  for pulling all coefficients, standard errors, and p-values from from multiple sectors into a single DataFrame. The second, called  format_regression_tables , creates formatted tables for presentation that can be exported as a text file, csv file, or LaTeX file with some stylized syntax.   Tip  LaTeX users : The method  format_regression_table  can output a table into a csv file with some desired LaTeX syntax. This can be done by specifying  format = '.csv'  and  'latex_syntax'=True . This option allows users to manipulate the tables in spreadsheet software while retaining LaTeX syntax.  We recommend reading the file into the spreadsheet software as 'text data' so that it does not try to interpret the formatting of the table entries.    The gme package also has several ways to save the results to a file, either in full or in a space-saving slim version. See the API Reference portion of this documentation for further information.       Had their been multiple sectors, we could have indicated so by adding the input  sector_var_name = 'sector_column'  in the declaration of the EstimationData.\u00a0 \u21a9    Additionally, the results of the estimation are saved as a attribute of the estimation model--- EstimationModel.results_dict ---and can be retrieved that way as well.\u00a0 \u21a9    For more details about the  statsmodels  results object, see  http://www.statsmodels.org/0.6.1/generated/statsmodels.genmod.generalized_linear_model.GLMResults.html .\u00a0 \u21a9",
            "title": "Viewing, formatting, and outputting the results"
        },
        {
            "location": "/estimate_technical/",
            "text": "MathJax.Hub.Config({\n  TeX: { equationNumbers: { autoNumber: \"AMS\" } }\n});\n\n\n\n\n\n\n\nGravity Estimation Methodology\n\n\nTheory-based gravity equation\n\n\nThe GME module estimates the \nstructural gravity equation\n \\eqref{eq:gravity} using the Poisson Pseudo Maximum Likelihood (PPML) estimator, a special case of the the Generalized Linear Model (GLM) framework.\n\n\n\n\n\\begin{equation}\n    X_{ij} =\\frac{Y_i E_j}{Y}\\left(\\frac{t_{ij}}{S_i P_j}\\right)^{1-\\sigma}.\n    \\label{eq:gravity}\n\\end{equation}\n\n\n\\begin{equation}\n    X_{ij} =\\frac{Y_i E_j}{Y}\\left(\\frac{t_{ij}}{S_i P_j}\\right)^{1-\\sigma}.\n    \\label{eq:gravity}\n\\end{equation}\n\n\n\n\nIn this equation, \nX_{ij}\nX_{ij}\n are the value of exports from country \ni\ni\n to country \nj\nj\n, \nY_{i}\nY_{i}\n is country \ni\ni\n's domestic production, \nE_{j}\nE_{j}\n is country \nj\nj\n's aggregate expenditure, \nY\nY\n is global production, \nt_{ij}\nt_{ij}\n is the bilateral cost of trading between country \ni\ni\n and country \nj\nj\n, and \n\\sigma\\\n\\sigma\\\n is the elasticity of substitution among goods from varying source countries. The structural terms \nS_{i}\nS_{i}\n and \nP_{j}\nP_{j}\n represent multilateral resistance within the exporting and importing countries (i.e the ease of market access for country \ni\ni\n's export, and the ease of market access for country \nj\nj\n's imports, respectively). \n\n\nWhen applying equation \\eqref{eq:gravity} to data using PPML, a variety of fixed effects are possible. One theory-consistent and flexible empirical form of the gravity equation when using panel data is\n\n\n\n\n\\begin{equation}\n    X_{ijt} =\\exp \\left[\\gamma_{it}+\\eta_{jt}+\\lambda_{ij}+\\beta Z_{ijt}\\right]+\\varepsilon_{ijt}\n    \\label{eq:PPML_gravity_panel}\n\\end{equation}\n\n\n\\begin{equation}\n    X_{ijt} =\\exp \\left[\\gamma_{it}+\\eta_{jt}+\\lambda_{ij}+\\beta Z_{ijt}\\right]+\\varepsilon_{ijt}\n    \\label{eq:PPML_gravity_panel}\n\\end{equation}\n\n\n\n\nIn equation \\eqref{eq:PPML_gravity_panel}, \n\\gamma_{it}\n\\gamma_{it}\n are exporter time-varying fixed effect, \n\\eta_{jt}\n\\eta_{jt}\n are importer time-varying fixed effects, \n\\lambda_{ij}\n\\lambda_{ij}\n are exporter-importer time-invariant fixed effects, and \nZ_{ijt}\nZ_{ijt}\n is the vector of time-variant bilateral determinants of trade, such as tariff levels.\n\n\nIf only cross-section data is available, a theory-consistent empirical form of the gravity equation could be\n\n\n\n\n\\begin{equation}\n    X_{ij} =\\exp \\left[\\gamma_{i}+\\eta_{j}+\\beta Z_{ij}\\right]+\\varepsilon_{ij}\n    \\label{eq:PPML_gravity_cross}\n\\end{equation}\n\n\n\\begin{equation}\n    X_{ij} =\\exp \\left[\\gamma_{i}+\\eta_{j}+\\beta Z_{ij}\\right]+\\varepsilon_{ij}\n    \\label{eq:PPML_gravity_cross}\n\\end{equation}\n\n\n\n\nIn this case, \n\\gamma_{it}\n\\gamma_{it}\n are exporter fixed effect, \n\\eta_{jt}\n\\eta_{jt}\n are importer fixed effects, and \nZ_{ij}\nZ_{ij}\n is the vector of bilateral determinants of trade, such as distance.\n\n\nEstimation Procedure\n\n\nThe method \nestimate\n performs a sector-by-sector GLM estimation based on a Poisson distribution with data diagnostics that help increase the likelihood of convergence. See \nestimate\n.  If sector_by_sector is specified, the routine is repeated for each sector individually, estimating a separate model each time. The estimate routine inherits all specifications from those supplied to the \nEstimationModel\n.\n\n\nTechnical Details of PPML Implementation\n\n\nWe implement PPML following \nSantos Silva and Tenreyro (2006)\n. The PPML assumes that the variance is proportional to the mean so that the only condition required for PPML to be consistent is the correct specification of the conditional mean. The PPML also gives the same weight to each observation in the estimation and so is desirable when there is not much available information on the nature of heteroscedasticity in the trade data. \nSantos Silva and Tenreyro (2006)\n provide simulation evidence that the PPML is well behaved in a wide range of situations and can deal with certain types of measurement error in the dependent variable. The PPML, being a non-linear estimator, is also able to handle zero trade flows in the estimation.\n\n\nCommon problems with PPML estimation include the non-existence of estimates due to perfect collinearity and numerical difficulties in running the algorithm.\n\n\nNon-existence of estimates\n\n\nSantos Silva and Tenreyro (2010)\n show that PPML estimates may not exist if there is perfect collinearity for the subsample with positive observations of the dependent variable (common in trade data where some countries do not trade in certain years or sectors and so are perfectly collinear when \nX_{ij}>0\nX_{ij}>0\n). In this scenario, either the estimation algorithm will fail to converge or convergence is spurious and characterized by a \u201cperfect\u201d fit for observations where \nX_{ij}=0\nX_{ij}=0\n. To check for non-existence, \nSantos Silva and Tenreyro (2011)\n use a short STATA code that first identifies and drops the problematic regressors before estimating it with PPML. Their code also issues a warning that the model is overfitting due to spurious convergence. We implement their STATA code in Python in order to obtain the same procedures for identifying and dropping problematic variables, testing for perfect collinearity and checking if the \nX_{ij}=0\nX_{ij}=0\n observations are perfectly predicted by the estimated model. All these diagnostics are stored as PPML diagnostics and available to the user after every GME estimation.\n\n\nNon-convergence\n\n\nSantos Silva and Tenreyro (2011)\n also find that sensitivity to numerical problems can prevent estimation algorithms from locating the maximum and finding PPML estimates that converge. In particular, these numerical issues arise when there are collinear regressors that have different magnitudes or regressors that are extremely, but not perfectly collinear. They recommend using the iterated, re-weighted least squares (IRLS) as the optimization algorithm to deal with such numerical complications, which is also the default method for GLM estimation in the \nstatsmodels\n package used by GME. Thus, the PPML estimator in GME is robust to numerical problems arising from different data configurations.",
            "title": "Methodology"
        },
        {
            "location": "/estimate_technical/#gravity-estimation-methodology",
            "text": "",
            "title": "Gravity Estimation Methodology"
        },
        {
            "location": "/estimate_technical/#theory-based-gravity-equation",
            "text": "The GME module estimates the  structural gravity equation  \\eqref{eq:gravity} using the Poisson Pseudo Maximum Likelihood (PPML) estimator, a special case of the the Generalized Linear Model (GLM) framework.   \\begin{equation}\n    X_{ij} =\\frac{Y_i E_j}{Y}\\left(\\frac{t_{ij}}{S_i P_j}\\right)^{1-\\sigma}.\n    \\label{eq:gravity}\n\\end{equation}  \\begin{equation}\n    X_{ij} =\\frac{Y_i E_j}{Y}\\left(\\frac{t_{ij}}{S_i P_j}\\right)^{1-\\sigma}.\n    \\label{eq:gravity}\n\\end{equation}   In this equation,  X_{ij} X_{ij}  are the value of exports from country  i i  to country  j j ,  Y_{i} Y_{i}  is country  i i 's domestic production,  E_{j} E_{j}  is country  j j 's aggregate expenditure,  Y Y  is global production,  t_{ij} t_{ij}  is the bilateral cost of trading between country  i i  and country  j j , and  \\sigma\\ \\sigma\\  is the elasticity of substitution among goods from varying source countries. The structural terms  S_{i} S_{i}  and  P_{j} P_{j}  represent multilateral resistance within the exporting and importing countries (i.e the ease of market access for country  i i 's export, and the ease of market access for country  j j 's imports, respectively).   When applying equation \\eqref{eq:gravity} to data using PPML, a variety of fixed effects are possible. One theory-consistent and flexible empirical form of the gravity equation when using panel data is   \\begin{equation}\n    X_{ijt} =\\exp \\left[\\gamma_{it}+\\eta_{jt}+\\lambda_{ij}+\\beta Z_{ijt}\\right]+\\varepsilon_{ijt}\n    \\label{eq:PPML_gravity_panel}\n\\end{equation}  \\begin{equation}\n    X_{ijt} =\\exp \\left[\\gamma_{it}+\\eta_{jt}+\\lambda_{ij}+\\beta Z_{ijt}\\right]+\\varepsilon_{ijt}\n    \\label{eq:PPML_gravity_panel}\n\\end{equation}   In equation \\eqref{eq:PPML_gravity_panel},  \\gamma_{it} \\gamma_{it}  are exporter time-varying fixed effect,  \\eta_{jt} \\eta_{jt}  are importer time-varying fixed effects,  \\lambda_{ij} \\lambda_{ij}  are exporter-importer time-invariant fixed effects, and  Z_{ijt} Z_{ijt}  is the vector of time-variant bilateral determinants of trade, such as tariff levels.  If only cross-section data is available, a theory-consistent empirical form of the gravity equation could be   \\begin{equation}\n    X_{ij} =\\exp \\left[\\gamma_{i}+\\eta_{j}+\\beta Z_{ij}\\right]+\\varepsilon_{ij}\n    \\label{eq:PPML_gravity_cross}\n\\end{equation}  \\begin{equation}\n    X_{ij} =\\exp \\left[\\gamma_{i}+\\eta_{j}+\\beta Z_{ij}\\right]+\\varepsilon_{ij}\n    \\label{eq:PPML_gravity_cross}\n\\end{equation}   In this case,  \\gamma_{it} \\gamma_{it}  are exporter fixed effect,  \\eta_{jt} \\eta_{jt}  are importer fixed effects, and  Z_{ij} Z_{ij}  is the vector of bilateral determinants of trade, such as distance.",
            "title": "Theory-based gravity equation"
        },
        {
            "location": "/estimate_technical/#estimation-procedure",
            "text": "The method  estimate  performs a sector-by-sector GLM estimation based on a Poisson distribution with data diagnostics that help increase the likelihood of convergence. See  estimate .  If sector_by_sector is specified, the routine is repeated for each sector individually, estimating a separate model each time. The estimate routine inherits all specifications from those supplied to the  EstimationModel .",
            "title": "Estimation Procedure"
        },
        {
            "location": "/estimate_technical/#technical-details-of-ppml-implementation",
            "text": "We implement PPML following  Santos Silva and Tenreyro (2006) . The PPML assumes that the variance is proportional to the mean so that the only condition required for PPML to be consistent is the correct specification of the conditional mean. The PPML also gives the same weight to each observation in the estimation and so is desirable when there is not much available information on the nature of heteroscedasticity in the trade data.  Santos Silva and Tenreyro (2006)  provide simulation evidence that the PPML is well behaved in a wide range of situations and can deal with certain types of measurement error in the dependent variable. The PPML, being a non-linear estimator, is also able to handle zero trade flows in the estimation.  Common problems with PPML estimation include the non-existence of estimates due to perfect collinearity and numerical difficulties in running the algorithm.",
            "title": "Technical Details of PPML Implementation"
        },
        {
            "location": "/estimate_technical/#non-existence-of-estimates",
            "text": "Santos Silva and Tenreyro (2010)  show that PPML estimates may not exist if there is perfect collinearity for the subsample with positive observations of the dependent variable (common in trade data where some countries do not trade in certain years or sectors and so are perfectly collinear when  X_{ij}>0 X_{ij}>0 ). In this scenario, either the estimation algorithm will fail to converge or convergence is spurious and characterized by a \u201cperfect\u201d fit for observations where  X_{ij}=0 X_{ij}=0 . To check for non-existence,  Santos Silva and Tenreyro (2011)  use a short STATA code that first identifies and drops the problematic regressors before estimating it with PPML. Their code also issues a warning that the model is overfitting due to spurious convergence. We implement their STATA code in Python in order to obtain the same procedures for identifying and dropping problematic variables, testing for perfect collinearity and checking if the  X_{ij}=0 X_{ij}=0  observations are perfectly predicted by the estimated model. All these diagnostics are stored as PPML diagnostics and available to the user after every GME estimation.",
            "title": "Non-existence of estimates"
        },
        {
            "location": "/estimate_technical/#non-convergence",
            "text": "Santos Silva and Tenreyro (2011)  also find that sensitivity to numerical problems can prevent estimation algorithms from locating the maximum and finding PPML estimates that converge. In particular, these numerical issues arise when there are collinear regressors that have different magnitudes or regressors that are extremely, but not perfectly collinear. They recommend using the iterated, re-weighted least squares (IRLS) as the optimization algorithm to deal with such numerical complications, which is also the default method for GLM estimation in the  statsmodels  package used by GME. Thus, the PPML estimator in GME is robust to numerical problems arising from different data configurations.",
            "title": "Non-convergence"
        },
        {
            "location": "/api_docs/EstimationData/",
            "text": "Class\n\n\ngme.EstimationData\n(\n                 \ndata_frame=None,\n                 name:str='unnamed',\n                 imp_var_name:str='importer',\n                 exp_var_name:str='exporter',\n                 year_var_name:str='year',\n                 trade_var_name:str=None,\n                 sector_var_name:str=None,\n                 notes:List[str]=[]\n)\n\n\nDescription\n\n\nAn object used for storing data for gravity modeling and producing some summary statistics.\n\n\nArguments\n\n\ndata_frame\n: \nPandas.DataFrame\n \n \u2003 A DataFrame containing trade, gravity, etc. data. \n\n\nname\n: (optional) \nstr\n \n \u2003 A name for the dataset.\n\n\nimp_var_name\n: \nstr\n \n \u2003 The name of the column containing importer IDs.\n\n\nexp_var_name\n: \nstr\n \n \u2003 The name of the column containing exporter IDs.\n\n\nyear_var_name\n: \nstr\n \n \u2003 The name of the column containing year data. \n\n\ntrade_var_name\n: (optional) \nstr\n \n \u2003 The name of the column containing trade data. \n\n\nsector_var_name\n: (optional) \nstr\n \n \u2003 The name of the column containing sector/industry/product IDs.\n\n\nnotes\n: (optional) \nstr\n \n \u2003 A string to be included as a note n the object. \n\n\nAttributes\n\n\ndata_frame\n: \nPandas.DataFrame\n \n \u2003 The supplied DataFrame. \n\n\nname\n: \nstr\n \n \u2003 The supplied data name. \n\n\nimp_var_name\n: \nstr\n \n \u2003 The name of the column containing importer IDs. \n\n\nexp_var_name\n: \nstr\n \n \u2003 The name of the column containing exporter IDs. \n\n\nyear_var_name\n: \nstr\n \n \u2003 The name of the column containing year data. \n\n\ntrade_var_name\n: \nstr\n \n \u2003 The name of the column containing trade data. \n\n\nsector_var_name\n: \nstr\n \n \u2003 The name of the column containing sector/industry/product IDs. \n\n\nnotes\n: \nList[str]\n \n \u2003 A list of notes. \n\n\nnumber_of_exporters\n: \nint\n \n \u2003 The number of unique exporter IDs in the dataset. \n\n\nnumber_of_importers\n: \nint\n \n \u2003 The number of unique importer IDs in the dataset. \n\n\nshape\n: \nList[int]\n \n \u2003 The dimensions of the dataset. \n\n\ncountries\n: \nList[str]\n \n \u2003 A list of the unique country IDs in the dataset. \n\n\nnumber_of_countries\n: \nint\n \n \u2003 The number of unique country IDs in the dataset. \n\n\nnumber_of_years\n: \nint\n \n \u2003 The number of years in the dataset \n\n\ncolumns\n: \nList[str]\n \n \u2003 A list of column names in the dataset. \n\n\nnumber_of_sectors\n: \nint\n \n \u2003 If a sector is specified, the number of unique sector IDs in the dataset. \n\n\nMethods\n\n\ntablulate_by_group\n:\n \n \u2003 Summarize columns by a user-specified grouping. Can be used to tabulate, aggregate, \n \n \u2003 summarize,etc. data.\n\n\n\u2003 \nArguments:\n \n \n\n\n\u2003\u2003 \ntab_variables\n: \nList[str]\n \n \n        \u2003\u2003\u2003 Column names of variables to be tabulated\n\n\n\u2003\u2003 \nby_group\n: \nList[str]\n \n\n        \u2003\u2003\u2003 Column names of variables by which to group observations for tabulation.\n\n\n\u2003\u2003 \nhow\n: \nList[str]\n \n\n         \u2003\u2003\u2003 The method by which to combine observations within a group. Can accept \n\n         \u2003\u2003\u2003 'count', 'mean',  'median', 'min', 'max', 'sum', 'prod', 'std', and 'var'. It may work \n\n         \u2003\u2003\u2003 with other numpy or pandas functions.\n\n\n\u2003\nReturns\n: \nPandas.DataFrame\n \n \n    \u2003\u2003 A DataFrame of tabulated values for each group.\n\n\nyear_list\n:\n \n \u2003 Returns a list of years present in the data. \n\n\ncountries_each_year\n:\n \n \u2003 Returns a dictionary keyed by year ID containing a list of country IDs present in each \n \n \u2003 corresponding year. \n\n\nsector_list\n:\n \n \u2003   Returns a list of unique sector IDs \n\n\ndtypes\n:\n \n \u2003 Returns the data types of the columns in the EstimationData.data_frame using\n \n \u2003 Pandas.DataFrame.dtypes(). See Pandas documentation for more information.\n\n\ninfo\n:\n \n \u2003 Print summary information about EstimationData.data_frame using\n \n \u2003 Pandas.DataFrame.dtypes(). See Pandas documentation for more information.\n\n\ndescribe\n:\n \n \u2003 Generates some descriptive statistics for EstimationData.data_frame using\n \n \u2003 Pandas.DataFrame.describe(). See Pandas documentation for more information.\n\n\nadd_note\n:\n \n \u2003 Add a note to the list of notes in 'notes' attribute.\n\n\n\u2003 \nArguments\n: \n\n\n\u2003\u2003 \nnote\n: \nstr\n \n\n\u2003\u2003\u2003 A note to add to EstimationData. \n\n\n\u2003 \nReturns\n: \nNone\n\n\nExamples\n\n\n# Load a DataFrame\n\n\n>>>\n \nimport\n \npandas\n \nas\n \npd\n\n\n>>>\n \ngravity_data\n \n=\n \npd\n.\nread_csv\n(\n'https://www.usitc.gov/data/gravity/example_trade_and_grav_data_small.csv'\n)\n\n\n>>>\n \ngravity_data\n.\nhead\n(\n5\n)\n\n  \nimporter\n \nexporter\n  \nyear\n   \ntrade_value\n  \nagree_pta\n  \ncommon_language\n  \\\n\n0\n      \nAUS\n      \nBRA\n  \n1989\n  \n3.035469e+08\n        \n0.0\n              \n1.0\n\n\n1\n      \nAUS\n      \nCAN\n  \n1989\n  \n8.769946e+08\n        \n0.0\n              \n1.0\n\n\n2\n      \nAUS\n      \nCHE\n  \n1989\n  \n4.005245e+08\n        \n0.0\n              \n1.0\n\n\n3\n      \nAUS\n      \nDEU\n  \n1989\n  \n2.468977e+09\n        \n0.0\n              \n0.0\n\n\n4\n      \nAUS\n      \nDNK\n  \n1989\n  \n1.763072e+08\n        \n0.0\n              \n1.0\n\n   \ncontiguity\n  \nlog_distance\n\n\n0\n         \n0.0\n      \n9.553332\n\n\n1\n         \n0.0\n      \n9.637676\n\n\n2\n         \n0.0\n      \n9.687557\n\n\n3\n         \n0.0\n      \n9.675007\n\n\n4\n         \n0.0\n      \n9.657311\n\n\n\nexample_estimation_data\n \n=\n \nEstimationData\n(\ngravity_data\n,\n\n                                 \nimp_var_name\n=\n'importer'\n,\n\n                                 \nexp_var_name\n=\n'exporter'\n,\n\n                                 \ntrade_var_name\n=\n'trade_value'\n,\n\n                                 \nyear_var_name\n=\n'year'\n,\n\n                                 \nnotes\n=\n'Downloaded from https://www.usitc.gov/data/gravity/example_trade_and_grav_data_small.csv'\n)\n\n\n\n# tabulate_by_group\n\n\n# Sum trade value by importer and year\n\n\n>>>\n \naggregated_data\n \n=\n \nexample_estimation_data\n.\ntabulate_by_group\n(\ntab_variables\n \n=\n \n[\n'trade_value'\n],\n\n\n...\n                                                         \nby_group\n \n=\n \n[\n'importer'\n,\n \n'year'\n],\n\n\n...\n                                                         \nhow\n \n=\n \n[\n'sum'\n])\n\n\n>>>\n \naggregated_data\n.\nhead\n(\n5\n)\n\n  \nimporter_\n  \nyear_\n  \ntrade_value_sum\n\n\n0\n       \nARG\n   \n1989\n     \n0.000000e+00\n\n\n1\n       \nARG\n   \n1990\n     \n0.000000e+00\n\n\n2\n       \nARG\n   \n1991\n     \n0.000000e+00\n\n\n3\n       \nARG\n   \n1992\n     \n0.000000e+00\n\n\n4\n       \nARG\n   \n1993\n     \n1.593530e+10\n\n\n\n# Summarize minimum and maximum trade flows between each trading pair\n\n\n>>>\n \nsummarized_data\n \n=\n \nexample_estimation_data\n.\ntabulate_by_group\n(\ntab_variables\n \n=\n \n[\n'trade_value'\n],\n\n\n...\n                                                         \nby_group\n \n=\n \n[\n'importer'\n,\n \n'exporter'\n],\n\n\n...\n                                                         \nhow\n \n=\n \n[\n'min'\n,\n'max'\n])\n\n\n>>>\n \nsummarized_data\n.\nhead\n(\n5\n)\n\n  \nimporter_\n \nexporter_\n  \ntrade_value_min\n  \ntrade_value_max\n\n\n0\n       \nARG\n       \nAUS\n              \n0.0\n     \n4.095529e+08\n\n\n1\n       \nARG\n       \nAUT\n              \n0.0\n     \n2.986187e+08\n\n\n2\n       \nARG\n       \nBEL\n              \n0.0\n     \n7.669537e+08\n\n\n3\n       \nARG\n       \nBOL\n              \n0.0\n     \n2.743706e+09\n\n\n4\n       \nARG\n       \nBRA\n              \n0.0\n     \n2.218091e+10\n\n\n\n# year_list\n\n\n>>>\n \nexample_estimation_data\n.\nyear_list\n()\n\n\n[\n1989\n,\n\n \n1990\n,\n\n \n1991\n,\n\n \n1992\n,\n\n \n...\n\n\n\n# countries_each_year\n\n\n>>>\n \ncountries\n \n=\n \nexample_estimation_data\n.\ncountries_each_year\n()\n\n\n>>>\n \ncountries\n.\nkeys\n()\n\n\ndict_keys\n([\n1989\n,\n \n1990\n,\n \n1991\n,\n \n1992\n,\n \n1993\n,\n \n1994\n,\n \n1995\n,\n \n1996\n,\n \n1997\n,\n \n1998\n,\n \n1999\n,\n \n2000\n,\n \n2001\n,\n \n2002\n,\n \n2003\n,\n \n2004\n,\n \n2005\n,\n \n2006\n,\n \n2007\n,\n \n2008\n,\n \n2009\n,\n \n2010\n,\n \n2011\n,\n \n2012\n,\n \n2013\n,\n \n2014\n,\n \n2015\n])\n\n\n>>>\n \ncountries\n[\n1989\n]\n\n\n[\n'ESP'\n,\n\n \n'SGP'\n,\n\n \n'PHL'\n,\n\n \n'NGA'\n,\n\n \n'VEN'\n,\n\n \n...\n\n\n\n# dtypes\n\n\n>>>\n \nexample_estimation_data\n.\ndtypes\n()\n\n\nimporter\n            \nobject\n\n\nexporter\n            \nobject\n\n\nyear\n                 \nint64\n\n\ntrade_value\n        \nfloat64\n\n\nagree_pta\n          \nfloat64\n\n\ncommon_language\n    \nfloat64\n\n\ncontiguity\n         \nfloat64\n\n\nlog_distance\n       \nfloat64\n\n\ndtype\n:\n \nobject\n\n\n\n>>>\n \nexample_estimation_data\n.\ninfo\n()\n\n\n<\nclass\n \n'\npandas\n.\ncore\n.\nframe\n.\nDataFrame\n'>\n\n\nRangeIndex\n:\n \n98612\n \nentries\n,\n \n0\n \nto\n \n98611\n\n\nData\n \ncolumns\n \n(\ntotal\n \n8\n \ncolumns\n):\n\n\nimporter\n           \n98612\n \nnon\n-\nnull\n \nobject\n\n\nexporter\n           \n98612\n \nnon\n-\nnull\n \nobject\n\n\nyear\n               \n98612\n \nnon\n-\nnull\n \nint64\n\n\ntrade_value\n        \n98612\n \nnon\n-\nnull\n \nfloat64\n\n\nagree_pta\n          \n97676\n \nnon\n-\nnull\n \nfloat64\n\n\ncommon_language\n    \n97676\n \nnon\n-\nnull\n \nfloat64\n\n\ncontiguity\n         \n97676\n \nnon\n-\nnull\n \nfloat64\n\n\nlog_distance\n       \n97676\n \nnon\n-\nnull\n \nfloat64\n\n\ndtypes\n:\n \nfloat64\n(\n5\n),\n \nint64\n(\n1\n),\n \nobject\n(\n2\n)\n\n\nmemory\n \nusage\n:\n \n6.0\n+\n \nMB\n\n\n\n# describe\n\n\n>>>\n \nexample_estimation_data\n.\ndescribe\n()\n\n               \nyear\n   \ntrade_value\n     \nagree_pta\n  \ncommon_language\n  \\\n\ncount\n  \n98612.000000\n  \n9.861200e+04\n  \n97676.000000\n     \n97676.000000\n\n\nmean\n    \n2002.210441\n  \n1.856316e+09\n      \n0.381547\n         \n0.380646\n\n\nstd\n        \n7.713050\n  \n1.004735e+10\n      \n0.485769\n         \n0.485548\n\n\nmin\n     \n1989.000000\n  \n0.000000e+00\n      \n0.000000\n         \n0.000000\n\n\n25\n%\n     \n1996.000000\n  \n1.084703e+06\n      \n0.000000\n         \n0.000000\n\n\n50\n%\n     \n2002.000000\n  \n6.597395e+07\n      \n0.000000\n         \n0.000000\n\n\n75\n%\n     \n2009.000000\n  \n6.125036e+08\n      \n1.000000\n         \n1.000000\n\n\nmax\n     \n2015.000000\n  \n4.977686e+11\n      \n1.000000\n         \n1.000000\n\n\n         \ncontiguity\n  \nlog_distance\n\n\ncount\n  \n97676.000000\n  \n97676.000000\n\n\nmean\n       \n0.034051\n      \n8.722631\n\n\nstd\n        \n0.181362\n      \n0.818818\n\n\nmin\n        \n0.000000\n      \n5.061335\n\n\n25\n%\n        \n0.000000\n      \n8.222970\n\n\n50\n%\n        \n0.000000\n      \n9.012502\n\n\n75\n%\n        \n0.000000\n      \n9.303026\n\n\nmax\n        \n1.000000\n      \n9.890765\n\n\n\n# notes\n\n\n>>>\n \nexample_estimation_data\n.\nadd_note\n(\n'year IDs are integers'\n)\n\n\n>>>\n \nexample_estimation_data\n.\nnotes\n\n\n[\n'Downloaded from https://www.usitc.gov/data/gravity/example_trade_and_grav_data_small.csv'\n,\n\n\n'year IDs are integers'\n]",
            "title": "EstimationData"
        },
        {
            "location": "/api_docs/EstimationData/#class",
            "text": "gme.EstimationData (\n                  data_frame=None,\n                 name:str='unnamed',\n                 imp_var_name:str='importer',\n                 exp_var_name:str='exporter',\n                 year_var_name:str='year',\n                 trade_var_name:str=None,\n                 sector_var_name:str=None,\n                 notes:List[str]=[] )",
            "title": "Class"
        },
        {
            "location": "/api_docs/EstimationData/#description",
            "text": "An object used for storing data for gravity modeling and producing some summary statistics.",
            "title": "Description"
        },
        {
            "location": "/api_docs/EstimationData/#arguments",
            "text": "data_frame :  Pandas.DataFrame  \n \u2003 A DataFrame containing trade, gravity, etc. data.   name : (optional)  str  \n \u2003 A name for the dataset.  imp_var_name :  str  \n \u2003 The name of the column containing importer IDs.  exp_var_name :  str  \n \u2003 The name of the column containing exporter IDs.  year_var_name :  str  \n \u2003 The name of the column containing year data.   trade_var_name : (optional)  str  \n \u2003 The name of the column containing trade data.   sector_var_name : (optional)  str  \n \u2003 The name of the column containing sector/industry/product IDs.  notes : (optional)  str  \n \u2003 A string to be included as a note n the object.",
            "title": "Arguments"
        },
        {
            "location": "/api_docs/EstimationData/#attributes",
            "text": "data_frame :  Pandas.DataFrame  \n \u2003 The supplied DataFrame.   name :  str  \n \u2003 The supplied data name.   imp_var_name :  str  \n \u2003 The name of the column containing importer IDs.   exp_var_name :  str  \n \u2003 The name of the column containing exporter IDs.   year_var_name :  str  \n \u2003 The name of the column containing year data.   trade_var_name :  str  \n \u2003 The name of the column containing trade data.   sector_var_name :  str  \n \u2003 The name of the column containing sector/industry/product IDs.   notes :  List[str]  \n \u2003 A list of notes.   number_of_exporters :  int  \n \u2003 The number of unique exporter IDs in the dataset.   number_of_importers :  int  \n \u2003 The number of unique importer IDs in the dataset.   shape :  List[int]  \n \u2003 The dimensions of the dataset.   countries :  List[str]  \n \u2003 A list of the unique country IDs in the dataset.   number_of_countries :  int  \n \u2003 The number of unique country IDs in the dataset.   number_of_years :  int  \n \u2003 The number of years in the dataset   columns :  List[str]  \n \u2003 A list of column names in the dataset.   number_of_sectors :  int  \n \u2003 If a sector is specified, the number of unique sector IDs in the dataset.",
            "title": "Attributes"
        },
        {
            "location": "/api_docs/EstimationData/#methods",
            "text": "tablulate_by_group :  \n \u2003 Summarize columns by a user-specified grouping. Can be used to tabulate, aggregate,   \n \u2003 summarize,etc. data.  \u2003  Arguments:      \u2003\u2003  tab_variables :  List[str]    \n        \u2003\u2003\u2003 Column names of variables to be tabulated  \u2003\u2003  by_group :  List[str]   \n        \u2003\u2003\u2003 Column names of variables by which to group observations for tabulation.  \u2003\u2003  how :  List[str]   \n         \u2003\u2003\u2003 The method by which to combine observations within a group. Can accept  \n         \u2003\u2003\u2003 'count', 'mean',  'median', 'min', 'max', 'sum', 'prod', 'std', and 'var'. It may work  \n         \u2003\u2003\u2003 with other numpy or pandas functions.  \u2003 Returns :  Pandas.DataFrame    \n    \u2003\u2003 A DataFrame of tabulated values for each group.  year_list :  \n \u2003 Returns a list of years present in the data.   countries_each_year :  \n \u2003 Returns a dictionary keyed by year ID containing a list of country IDs present in each   \n \u2003 corresponding year.   sector_list :  \n \u2003   Returns a list of unique sector IDs   dtypes :  \n \u2003 Returns the data types of the columns in the EstimationData.data_frame using  \n \u2003 Pandas.DataFrame.dtypes(). See Pandas documentation for more information.  info :  \n \u2003 Print summary information about EstimationData.data_frame using  \n \u2003 Pandas.DataFrame.dtypes(). See Pandas documentation for more information.  describe :  \n \u2003 Generates some descriptive statistics for EstimationData.data_frame using  \n \u2003 Pandas.DataFrame.describe(). See Pandas documentation for more information.  add_note :  \n \u2003 Add a note to the list of notes in 'notes' attribute.  \u2003  Arguments :   \u2003\u2003  note :  str   \n\u2003\u2003\u2003 A note to add to EstimationData.   \u2003  Returns :  None",
            "title": "Methods"
        },
        {
            "location": "/api_docs/EstimationData/#examples",
            "text": "# Load a DataFrame  >>>   import   pandas   as   pd  >>>   gravity_data   =   pd . read_csv ( 'https://www.usitc.gov/data/gravity/example_trade_and_grav_data_small.csv' )  >>>   gravity_data . head ( 5 ) \n   importer   exporter    year     trade_value    agree_pta    common_language   \\ 0        AUS        BRA    1989    3.035469e+08          0.0                1.0  1        AUS        CAN    1989    8.769946e+08          0.0                1.0  2        AUS        CHE    1989    4.005245e+08          0.0                1.0  3        AUS        DEU    1989    2.468977e+09          0.0                0.0  4        AUS        DNK    1989    1.763072e+08          0.0                1.0 \n    contiguity    log_distance  0           0.0        9.553332  1           0.0        9.637676  2           0.0        9.687557  3           0.0        9.675007  4           0.0        9.657311  example_estimation_data   =   EstimationData ( gravity_data , \n                                  imp_var_name = 'importer' , \n                                  exp_var_name = 'exporter' , \n                                  trade_var_name = 'trade_value' , \n                                  year_var_name = 'year' , \n                                  notes = 'Downloaded from https://www.usitc.gov/data/gravity/example_trade_and_grav_data_small.csv' )  # tabulate_by_group  # Sum trade value by importer and year  >>>   aggregated_data   =   example_estimation_data . tabulate_by_group ( tab_variables   =   [ 'trade_value' ],  ...                                                           by_group   =   [ 'importer' ,   'year' ],  ...                                                           how   =   [ 'sum' ])  >>>   aggregated_data . head ( 5 ) \n   importer_    year_    trade_value_sum  0         ARG     1989       0.000000e+00  1         ARG     1990       0.000000e+00  2         ARG     1991       0.000000e+00  3         ARG     1992       0.000000e+00  4         ARG     1993       1.593530e+10  # Summarize minimum and maximum trade flows between each trading pair  >>>   summarized_data   =   example_estimation_data . tabulate_by_group ( tab_variables   =   [ 'trade_value' ],  ...                                                           by_group   =   [ 'importer' ,   'exporter' ],  ...                                                           how   =   [ 'min' , 'max' ])  >>>   summarized_data . head ( 5 ) \n   importer_   exporter_    trade_value_min    trade_value_max  0         ARG         AUS                0.0       4.095529e+08  1         ARG         AUT                0.0       2.986187e+08  2         ARG         BEL                0.0       7.669537e+08  3         ARG         BOL                0.0       2.743706e+09  4         ARG         BRA                0.0       2.218091e+10  # year_list  >>>   example_estimation_data . year_list ()  [ 1989 , \n  1990 , \n  1991 , \n  1992 , \n  ...  # countries_each_year  >>>   countries   =   example_estimation_data . countries_each_year ()  >>>   countries . keys ()  dict_keys ([ 1989 ,   1990 ,   1991 ,   1992 ,   1993 ,   1994 ,   1995 ,   1996 ,   1997 ,   1998 ,   1999 ,   2000 ,   2001 ,   2002 ,   2003 ,   2004 ,   2005 ,   2006 ,   2007 ,   2008 ,   2009 ,   2010 ,   2011 ,   2012 ,   2013 ,   2014 ,   2015 ])  >>>   countries [ 1989 ]  [ 'ESP' , \n  'SGP' , \n  'PHL' , \n  'NGA' , \n  'VEN' , \n  ...  # dtypes  >>>   example_estimation_data . dtypes ()  importer              object  exporter              object  year                   int64  trade_value          float64  agree_pta            float64  common_language      float64  contiguity           float64  log_distance         float64  dtype :   object  >>>   example_estimation_data . info ()  < class   ' pandas . core . frame . DataFrame '>  RangeIndex :   98612   entries ,   0   to   98611  Data   columns   ( total   8   columns ):  importer             98612   non - null   object  exporter             98612   non - null   object  year                 98612   non - null   int64  trade_value          98612   non - null   float64  agree_pta            97676   non - null   float64  common_language      97676   non - null   float64  contiguity           97676   non - null   float64  log_distance         97676   non - null   float64  dtypes :   float64 ( 5 ),   int64 ( 1 ),   object ( 2 )  memory   usage :   6.0 +   MB  # describe  >>>   example_estimation_data . describe () \n                year     trade_value       agree_pta    common_language   \\ count    98612.000000    9.861200e+04    97676.000000       97676.000000  mean      2002.210441    1.856316e+09        0.381547           0.380646  std          7.713050    1.004735e+10        0.485769           0.485548  min       1989.000000    0.000000e+00        0.000000           0.000000  25 %       1996.000000    1.084703e+06        0.000000           0.000000  50 %       2002.000000    6.597395e+07        0.000000           0.000000  75 %       2009.000000    6.125036e+08        1.000000           1.000000  max       2015.000000    4.977686e+11        1.000000           1.000000 \n\n          contiguity    log_distance  count    97676.000000    97676.000000  mean         0.034051        8.722631  std          0.181362        0.818818  min          0.000000        5.061335  25 %          0.000000        8.222970  50 %          0.000000        9.012502  75 %          0.000000        9.303026  max          1.000000        9.890765  # notes  >>>   example_estimation_data . add_note ( 'year IDs are integers' )  >>>   example_estimation_data . notes  [ 'Downloaded from https://www.usitc.gov/data/gravity/example_trade_and_grav_data_small.csv' ,  'year IDs are integers' ]",
            "title": "Examples"
        },
        {
            "location": "/api_docs/EstimationModel/",
            "text": "Class\n\n\ngme.\nEstimationModel\n(\nestimation_data: gme.EstimationData = None, \n                                lhs_var: str = None,\n                                rhs_var: List[str] = None,\n                                sector_by_sector: bool = False,\n                                drop_imp_exp: List[str] = [ ],\n                                drop_imp: List[str] = [ ],\n                                drop_exp: List[str] = [ ],\n                                keep_imp_exp: List[str] = [ ],\n                                keep_imp: List[str] = [ ],\n                                keep_exp: List[str] = [ ],\n                                drop_years: List[str] = [ ],\n                                keep_years: List[str] = [ ],\n                                drop_missing: bool = True,\n                                variables_to_drop_missing: List[str] = None,\n                                fixed_effects:List[Union[str,List[str]]] = [ ],\n                                omit_fixed_effect:List[Union[str,List[str]]] = ['exporter','exporter-year', 'year'],\n                                std_errors:str = 'HC1',\n                                iteration_limit:int = 1000,\n                                drop_intratrade:bool = False,\n                                retain_modified_data:bool = False,\n                                full_results:bool = False\n)\n\n\nDescription\n\n\nThe class used to specify and run an gravity estimation.  A gme.EstimationData must be supplied along with a collection of largely optional arguments that specify variables to include, fixed effects to create, and how to perform the regression, among other options.  After the definition of the model, additional methods such as .estimate(), which performs the PPML estimation, or .combine_sector_results(), which combines the results for each sector (if applicable) can be called.\n\n\nArguments\n\n\nestimation_data\n: \ngme.EstimationData\n \n\n \u2003 A GME EstimationData to use as the basis of the gravity model. \n\n\nspec_name\n: (optional) \nstr\n \n\n \u2003 A name for the model. \n\n\nlhs_var\n: \nstr\n \n\n \u2003 The column name of the variable to be used as the dependent or 'left-hand-side' variable in the\n \u2003 regression. \n\n\nrhs_var\n: \nList[str]\n \n\n \u2003 A list of column names for the independent or 'right-hand-side' variable(s) to be used in the \n\n \u2003 regression. \n\n\nsector_by_sector\n: \nbool\n \n\n \u2003 If true, separate models are estimated for each sector, individually.  Default is False. If True, \n\n \u2003 a sector_var_name must have been supplied to the EstimationData. \n\n\ndrop_imp_exp\n: (optional) \nList[str]\n \n\n \u2003 A list of country identifiers to be excluded from the estimation when they appear as an\n \n \u2003 importer or exporter. \n\n\ndrop_imp\n: (optional) \nList[str]\n \n\n \u2003 A list of country identifiers to be excluded from the estimation when they appear as an \n \n \u2003 importer. \n\n\ndrop_exp\n: (optional) \nList[str]\n \n\n \u2003 A list of country identifiers to be excluded from the estimation when they appear as an \n \n \u2003 exporter. \n\n\nkeep_imp_exp\n: (optional) \nList[str]\n \n\n \u2003 A list of countries to include in the estimation as either importers or exporters. All others not \n\n \u2003 specified are excluded. \n\n\nkeep_imp\n: (optional) \nList[str]\n \n\n \u2003 A list of countries to include in the estimation as importers. All others not specified are \n\n \u2003 excluded. \n\n\nkeep_exp\n: (optional) \nList[str]\n \n\n \u2003 A list of countries to include in the estimation as exporters. All others not specified are \n\n \u2003 excluded. \n\n\ndrop_years\n: (optional) \nlist\n \n\n \u2003 A list of years to exclude from the estimation. The list elements should match the dtype of \n\n \u2003 the year column in the EstimationData. \n\n\nkeep_years\n: (optional) \nlist\n \n\n \u2003 A list of years to include in the estimation. The list elements should match the dtype of the \n\n \u2003 year column in the EstimationData. \n\n\ndrop_missing\n: \nbool\n \n\n \u2003 If True, rows with missing values are dropped. Default is true, which drops if observations \n \n \u2003 are missing in any of the columns specified by lhs_var or rhs_var. \n\n\nvariables_to_drop_missing\n: (optional) \nList[str]\n   \n\n\u2003 A list of column names for specifying which columns to check for missing values when \n \n\u2003 dropping rows. \n\n\nfixed_effects\n: (optional) \nList[Union[str,List[str]]]\n  \n\n\u2003 A list of variables to construct fixed effects based on. Can accept single string entries, which \n\n\u2003 create fixed effects corresponding to that variable or lists of strings that create fixed effects \n\n\u2003 corresponding to the interaction of the list items. For example, \n \n\u2003 \nfixed_effects = ['importer',['exporter','year']]\n would create a set of importer fixed effects \n \n\u2003 and a set of exporter-year fixed effects. \n\n\nomit_fixed_effect\n: (optional) \nList[Union[str,List[str]]]\n\n\u2003 The fixed effect category from which to drop a fixed effect to avoid collinearity. The entry \n\n\u2003 should be a subset of the list supplied for fixed_effects. In each case, the last fixed effect \n \n\u2003 is dropped. If not specified, the colinearity diagnostics will identify a column to drop on its \n \n\u2003 own. \n\n\nstd_errors\n: (optional) \nstr\n    \n\n \u2003 Specifies the type of standard errors to be computed. Default is HC1, heteroskedascticity \n \n \u2003 robust errors. See \nstatsmodels documentation\n for alternative options. \n\n\niteration_limit\n: (optional) \nint\n   \n\n \u2003 Upper limit on the number of iterations for the estimation procedure. Default is 1000.  \n\n\ndrop_intratrade\n: (optional) \nbool\n  \n\n\u2003 If True, intra-national trade flows (importer == exporter) are excluded from the regression. \n \n\u2003 Default is False. \n\n\nretain_modified_data\n: (optional) \nbool\n   \n\n \u2003 If True, the estimation DataFrames for each sector after they have been (potentially) modified\n \n \u2003 during the pre-diagnostics for collinearity and convergence issues. Default is False. \n \n \u2003 WARNING: these object sizes can be very large in memory so use with caution.  \n\n\nfull_results\n: \nbool\n \n\n \u2003 If True, estimate() returns the full results object from the GLM estimation.  These results can \n \n \u2003 be quite large as each estimated sector's results will contain a full copy of the data used for \n \n \u2003 its estimation, vectors of predicted values, and other memory intensive pieces of data. \n\n \u2003 If False, estimate() returns a smaller subset of the results that are likely most useful (e.g.  \n \n \u2003 .params, .nobs, .bse, .pvalues, .aic, .bic).  For a list of these attributes, see the documentation\n \n \u2003 for the function \nSlimResults\n. \n\n\nAttributes\n\n\nestimation_data\n:\n \n \u2003 Return the EstimationData. \n\n\nresults_dict\n:\n \n \u2003 Return the dictionary of regression results (after applying estimate method). \n\n\nmodified_data\n:\n \n \u2003 Return data modified data after removing problematic columns (after applying estimate\n \n \u2003 method) \n\n\nppml_diagnostics\n:\n \n \u2003 Return PPML estimation diagnostic information (after applying estimate method). See\n\n \u2003 \nestimate\n.  \n\n\nMethods\n\n\nestimate\n:\n \n \u2003 Estimate a PPML model. See \nestimate\n. \n\n\ncombine_sector_results\n:\n \n \u2003 Combine multiple result_dict entries into a single DataFrame. See \ncombine_sector_results\n.   \n\n\nformat_regression_table\n:\n \n \u2003 Format regression results into a text, csv, or LaTeX table for presentation. See \n \n \u2003 \nformat_regression_table\n \n\n\nExamples\n\n\n# Declare an EstimationModel\n\n\n>>>\n \nsample_estimation_model\n \n=\n \ngme\n.\nEstimationModel\n(\ndata_object\n \n=\n \ngme_data\n,\n\n\n...\n                                              \nlhs_var\n \n=\n \n'trade_value'\n,\n\n\n...\n                                              \nrhs_var\n \n=\n \n[\n'log_distance'\n,\n\n\n...\n                                              \n'agree_pta'\n,\n\n\n...\n                                              \n'common_language'\n,\n\n\n...\n                                              \n'contiguity'\n])\n\n\n\n# Estimate the model\n\n\n>>>\n \nsample_estimation_model\n.\nestimate\n()\n\n\n\n# Extract the results\n\n\n>>>\n \nresults_dictionary\n \n=\n \nsample_estimation_model\n.\nresults_dict\n\n\n\n# Write the estimates, p-values, and std. errors from all sectors to a .csv file.\n\n\n>>>\n \nsample_estimation_model\n.\ncombine_sector_results\n(\n\"c:\n\\\\\nfolder\n\\\\\nsaved_results.csv\"\n)\n \n\n\n# Create and export a formatted table of estimation results\n\n\n>>>\n \nsample_estimation_model\n.\nformat_regression_table\n(\nformat\n \n=\n \n'csv'\n,\n\n\n...\n                                                 \npath\n \n=\n \n\"c:\n\\\\\nfolder\n\\\\\nsaved_results.csv\"\n)",
            "title": "EstimationModel"
        },
        {
            "location": "/api_docs/EstimationModel/#class",
            "text": "gme. EstimationModel ( estimation_data: gme.EstimationData = None, \n                                lhs_var: str = None,\n                                rhs_var: List[str] = None,\n                                sector_by_sector: bool = False,\n                                drop_imp_exp: List[str] = [ ],\n                                drop_imp: List[str] = [ ],\n                                drop_exp: List[str] = [ ],\n                                keep_imp_exp: List[str] = [ ],\n                                keep_imp: List[str] = [ ],\n                                keep_exp: List[str] = [ ],\n                                drop_years: List[str] = [ ],\n                                keep_years: List[str] = [ ],\n                                drop_missing: bool = True,\n                                variables_to_drop_missing: List[str] = None,\n                                fixed_effects:List[Union[str,List[str]]] = [ ],\n                                omit_fixed_effect:List[Union[str,List[str]]] = ['exporter','exporter-year', 'year'],\n                                std_errors:str = 'HC1',\n                                iteration_limit:int = 1000,\n                                drop_intratrade:bool = False,\n                                retain_modified_data:bool = False,\n                                full_results:bool = False )",
            "title": "Class"
        },
        {
            "location": "/api_docs/EstimationModel/#description",
            "text": "The class used to specify and run an gravity estimation.  A gme.EstimationData must be supplied along with a collection of largely optional arguments that specify variables to include, fixed effects to create, and how to perform the regression, among other options.  After the definition of the model, additional methods such as .estimate(), which performs the PPML estimation, or .combine_sector_results(), which combines the results for each sector (if applicable) can be called.",
            "title": "Description"
        },
        {
            "location": "/api_docs/EstimationModel/#arguments",
            "text": "estimation_data :  gme.EstimationData   \n \u2003 A GME EstimationData to use as the basis of the gravity model.   spec_name : (optional)  str   \n \u2003 A name for the model.   lhs_var :  str   \n \u2003 The column name of the variable to be used as the dependent or 'left-hand-side' variable in the\n \u2003 regression.   rhs_var :  List[str]   \n \u2003 A list of column names for the independent or 'right-hand-side' variable(s) to be used in the  \n \u2003 regression.   sector_by_sector :  bool   \n \u2003 If true, separate models are estimated for each sector, individually.  Default is False. If True,  \n \u2003 a sector_var_name must have been supplied to the EstimationData.   drop_imp_exp : (optional)  List[str]   \n \u2003 A list of country identifiers to be excluded from the estimation when they appear as an  \n \u2003 importer or exporter.   drop_imp : (optional)  List[str]   \n \u2003 A list of country identifiers to be excluded from the estimation when they appear as an   \n \u2003 importer.   drop_exp : (optional)  List[str]   \n \u2003 A list of country identifiers to be excluded from the estimation when they appear as an   \n \u2003 exporter.   keep_imp_exp : (optional)  List[str]   \n \u2003 A list of countries to include in the estimation as either importers or exporters. All others not  \n \u2003 specified are excluded.   keep_imp : (optional)  List[str]   \n \u2003 A list of countries to include in the estimation as importers. All others not specified are  \n \u2003 excluded.   keep_exp : (optional)  List[str]   \n \u2003 A list of countries to include in the estimation as exporters. All others not specified are  \n \u2003 excluded.   drop_years : (optional)  list   \n \u2003 A list of years to exclude from the estimation. The list elements should match the dtype of  \n \u2003 the year column in the EstimationData.   keep_years : (optional)  list   \n \u2003 A list of years to include in the estimation. The list elements should match the dtype of the  \n \u2003 year column in the EstimationData.   drop_missing :  bool   \n \u2003 If True, rows with missing values are dropped. Default is true, which drops if observations   \n \u2003 are missing in any of the columns specified by lhs_var or rhs_var.   variables_to_drop_missing : (optional)  List[str]     \n\u2003 A list of column names for specifying which columns to check for missing values when   \n\u2003 dropping rows.   fixed_effects : (optional)  List[Union[str,List[str]]]    \n\u2003 A list of variables to construct fixed effects based on. Can accept single string entries, which  \n\u2003 create fixed effects corresponding to that variable or lists of strings that create fixed effects  \n\u2003 corresponding to the interaction of the list items. For example,   \n\u2003  fixed_effects = ['importer',['exporter','year']]  would create a set of importer fixed effects   \n\u2003 and a set of exporter-year fixed effects.   omit_fixed_effect : (optional)  List[Union[str,List[str]]] \n\u2003 The fixed effect category from which to drop a fixed effect to avoid collinearity. The entry  \n\u2003 should be a subset of the list supplied for fixed_effects. In each case, the last fixed effect   \n\u2003 is dropped. If not specified, the colinearity diagnostics will identify a column to drop on its   \n\u2003 own.   std_errors : (optional)  str      \n \u2003 Specifies the type of standard errors to be computed. Default is HC1, heteroskedascticity   \n \u2003 robust errors. See  statsmodels documentation  for alternative options.   iteration_limit : (optional)  int     \n \u2003 Upper limit on the number of iterations for the estimation procedure. Default is 1000.    drop_intratrade : (optional)  bool    \n\u2003 If True, intra-national trade flows (importer == exporter) are excluded from the regression.   \n\u2003 Default is False.   retain_modified_data : (optional)  bool     \n \u2003 If True, the estimation DataFrames for each sector after they have been (potentially) modified  \n \u2003 during the pre-diagnostics for collinearity and convergence issues. Default is False.   \n \u2003 WARNING: these object sizes can be very large in memory so use with caution.    full_results :  bool   \n \u2003 If True, estimate() returns the full results object from the GLM estimation.  These results can   \n \u2003 be quite large as each estimated sector's results will contain a full copy of the data used for   \n \u2003 its estimation, vectors of predicted values, and other memory intensive pieces of data.  \n \u2003 If False, estimate() returns a smaller subset of the results that are likely most useful (e.g.    \n \u2003 .params, .nobs, .bse, .pvalues, .aic, .bic).  For a list of these attributes, see the documentation  \n \u2003 for the function  SlimResults .",
            "title": "Arguments"
        },
        {
            "location": "/api_docs/EstimationModel/#attributes",
            "text": "estimation_data :  \n \u2003 Return the EstimationData.   results_dict :  \n \u2003 Return the dictionary of regression results (after applying estimate method).   modified_data :  \n \u2003 Return data modified data after removing problematic columns (after applying estimate  \n \u2003 method)   ppml_diagnostics :  \n \u2003 Return PPML estimation diagnostic information (after applying estimate method). See \n \u2003  estimate .",
            "title": "Attributes"
        },
        {
            "location": "/api_docs/EstimationModel/#methods",
            "text": "estimate :  \n \u2003 Estimate a PPML model. See  estimate .   combine_sector_results :  \n \u2003 Combine multiple result_dict entries into a single DataFrame. See  combine_sector_results .     format_regression_table :  \n \u2003 Format regression results into a text, csv, or LaTeX table for presentation. See   \n \u2003  format_regression_table",
            "title": "Methods"
        },
        {
            "location": "/api_docs/EstimationModel/#examples",
            "text": "# Declare an EstimationModel  >>>   sample_estimation_model   =   gme . EstimationModel ( data_object   =   gme_data ,  ...                                                lhs_var   =   'trade_value' ,  ...                                                rhs_var   =   [ 'log_distance' ,  ...                                                'agree_pta' ,  ...                                                'common_language' ,  ...                                                'contiguity' ])  # Estimate the model  >>>   sample_estimation_model . estimate ()  # Extract the results  >>>   results_dictionary   =   sample_estimation_model . results_dict  # Write the estimates, p-values, and std. errors from all sectors to a .csv file.  >>>   sample_estimation_model . combine_sector_results ( \"c: \\\\ folder \\\\ saved_results.csv\" )   # Create and export a formatted table of estimation results  >>>   sample_estimation_model . format_regression_table ( format   =   'csv' ,  ...                                                   path   =   \"c: \\\\ folder \\\\ saved_results.csv\" )",
            "title": "Examples"
        },
        {
            "location": "/api_docs/estimate_method/",
            "text": "Function\n\n\nestimate\n()\n\n\nDescription\n\n\nThe method \nestimate\n performs a sector-by-sector GLM estimation based on a Poisson distribution with data diagnostics that help increase the likelihood of convergence. If sector_by_sector is specified, the routine is repeated for each sector individually, estimating a separate model each time. The estimate routine inherits all specifications from those supplied to the \nEstimationModel\n. The routine follows several steps.\n\n\n\n\n\n\nCreates Fixed effects\n: Fixed effects are created based on the EstimationModel specification.\n\n\n\n\n\n\nPre-Diagnostics\n: Several steps are taken to increase the likelihood that the estimation will converge\n    successfully. \nClick here to technical details.\n\n\n\n\nPerfect Colinearity: Columns and observations that are perfectly collinear are identified and\n    excluded.\n\n\nInsufficient Variation: Variables in which there is an insufficient level of\n    variation for estimation are excluded. These are typically cases in which a country does not import or export at all for a given level of fixed effect.\n\n\n\n\n\n\n\n\nEstimate\n: Estimation is run using GLM.fit in statsmodels for the Poisson family distribution. Robust standard errors are computed using the HC1 version of the Huber-White estimator for heteroscedasticity consistent covariance matrix.\n\n\n\n\n\n\nPost-Diagnostics\n: A test for over-fit values as in \nSantos Silva and Tenreyro (2011)\n.\n\n\n\n\n\n\nResults\n: The method returns \nEstimationModel.results_dict\n and stores two others (\nEstimationModel.ppml_diagnostics\n and \nEstimationModel.modified_data\n) as attributes of the \nEstimationModel\n. \n\n\n\n\n\n\nEstimationModel.results_dict\n:  This is a dictionary of results objects from the statsmodels GLM.fit routine, each keyed using either the name of the sector if the estimation was sector-by-sector (i.e. \nsector_by_sector = True\n) or with the key 'all' if not. It is both returned and stored as \nEstimationModel.results_dict\n.\n1\n\n\n\n\n\n\nEstimationModel.ppml_diagnostics\n: A data frame containing a column of pre- and post-diagnostic information for each regression\n\n\n\n\n\n\nEstimationModel.modified_data\n: A dictionary using the same keys as results_dict, each containing the modified DataFrames created during the pre-diagnostic stages of the estimations. Because of the large memory footprint of this assignment, storing it is optional and only done if specified (i.e. \nEstimationModel.retain_modified_data = True\n)\n\n\n\n\n\n\n\n\n\n\nExample\n\n\n# Create fixed effects and specify sector by sector estimation\n\n\n>>>\n \ngme_data\n \n=\n \ngme\n.\nEstimationData\n(\ndata_frame\n \n=\n \nsample_data\n,\n\n                              \nimp_var_name\n \n=\n \n'importer'\n,\n\n                              \nexp_var_name\n \n=\n \n'exporter'\n,\n\n                              \nsector_var_name\n \n=\n \n'sector'\n\n                              \ntrade_var_name\n \n=\n \n'trade_value'\n,\n\n                              \nyear_var_name\n \n=\n \n'year'\n)\n\n\n\n>>>\n \nsample_estimation_model\n \n=\n \ngme\n.\nEstimationModel\n(\nestimation_data\n \n=\n \ngme_data\n,\n \n                                                \nlhs_var\n \n=\n \n'trade_value'\n,\n \n                                                \nrhs_var\n \n=\n \n[\n'log_distance'\n,\n'agree_pta'\n,\n'common_language'\n,\n'contiguity'\n],\n \n                                                \nfixed_effects\n \n=\n \n[\n'importer'\n,\n \n'exporter'\n],\n \n                                                \nkeep_years\n \n=\n \n[\n2013\n,\n \n2014\n,\n \n2015\n],\n\n                                                \nsector_by_sector\n \n=\n \nTrue\n)\n\n\n\n# Estimate the model\n\n\n>>>\n \nsample_estimation_model\n.\nestimate\n()\n\n\n\n# Generate post-diagnostics\n\n\n>>>\n \ndiag\n \n=\n \nsample_estimation_model\n.\nppml_diagnostics\n\n\n>>>\n \nprint\n(\ndiag\n)\n\n\nOverfit\n \nWarning\n                                                                 \nNo\n\n\nCollinearities\n                                                                  \nNo\n\n\nNumber\n \nof\n \nColumns\n \nExcluded\n                                                       \n3\n\n\nPerfectly\n \nCollinear\n \nVariables\n                                                   \n[]\n\n\nZero\n \nTrade\n \nVariables\n             \n[\nimporter_fe_IRN\n,\n \nimporter_fe_LBY\n,\n \nimporter_fe\n...\n\n\n\n# Extract the results to a new data frame and save to a .csv\n\n\n>>>\n \nresults_dictionary\n \n=\n \nsample_estimation_model\n.\nresults_dict\n(\n\"c:\n\\f\nolder\\saved_results.csv\"\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\nFor more details about the \nstatsmodels\n results object, see \nhttp://www.statsmodels.org/0.6.1/generated/statsmodels.genmod.generalized_linear_model.GLMResults.html\n.\u00a0\n\u21a9",
            "title": "estimate"
        },
        {
            "location": "/api_docs/estimate_method/#function",
            "text": "estimate ()",
            "title": "Function"
        },
        {
            "location": "/api_docs/estimate_method/#description",
            "text": "The method  estimate  performs a sector-by-sector GLM estimation based on a Poisson distribution with data diagnostics that help increase the likelihood of convergence. If sector_by_sector is specified, the routine is repeated for each sector individually, estimating a separate model each time. The estimate routine inherits all specifications from those supplied to the  EstimationModel . The routine follows several steps.    Creates Fixed effects : Fixed effects are created based on the EstimationModel specification.    Pre-Diagnostics : Several steps are taken to increase the likelihood that the estimation will converge\n    successfully.  Click here to technical details.   Perfect Colinearity: Columns and observations that are perfectly collinear are identified and\n    excluded.  Insufficient Variation: Variables in which there is an insufficient level of\n    variation for estimation are excluded. These are typically cases in which a country does not import or export at all for a given level of fixed effect.     Estimate : Estimation is run using GLM.fit in statsmodels for the Poisson family distribution. Robust standard errors are computed using the HC1 version of the Huber-White estimator for heteroscedasticity consistent covariance matrix.    Post-Diagnostics : A test for over-fit values as in  Santos Silva and Tenreyro (2011) .    Results : The method returns  EstimationModel.results_dict  and stores two others ( EstimationModel.ppml_diagnostics  and  EstimationModel.modified_data ) as attributes of the  EstimationModel .     EstimationModel.results_dict :  This is a dictionary of results objects from the statsmodels GLM.fit routine, each keyed using either the name of the sector if the estimation was sector-by-sector (i.e.  sector_by_sector = True ) or with the key 'all' if not. It is both returned and stored as  EstimationModel.results_dict . 1    EstimationModel.ppml_diagnostics : A data frame containing a column of pre- and post-diagnostic information for each regression    EstimationModel.modified_data : A dictionary using the same keys as results_dict, each containing the modified DataFrames created during the pre-diagnostic stages of the estimations. Because of the large memory footprint of this assignment, storing it is optional and only done if specified (i.e.  EstimationModel.retain_modified_data = True )",
            "title": "Description"
        },
        {
            "location": "/api_docs/estimate_method/#example",
            "text": "# Create fixed effects and specify sector by sector estimation  >>>   gme_data   =   gme . EstimationData ( data_frame   =   sample_data , \n                               imp_var_name   =   'importer' , \n                               exp_var_name   =   'exporter' , \n                               sector_var_name   =   'sector' \n                               trade_var_name   =   'trade_value' , \n                               year_var_name   =   'year' )  >>>   sample_estimation_model   =   gme . EstimationModel ( estimation_data   =   gme_data ,  \n                                                 lhs_var   =   'trade_value' ,  \n                                                 rhs_var   =   [ 'log_distance' , 'agree_pta' , 'common_language' , 'contiguity' ],  \n                                                 fixed_effects   =   [ 'importer' ,   'exporter' ],  \n                                                 keep_years   =   [ 2013 ,   2014 ,   2015 ], \n                                                 sector_by_sector   =   True )  # Estimate the model  >>>   sample_estimation_model . estimate ()  # Generate post-diagnostics  >>>   diag   =   sample_estimation_model . ppml_diagnostics  >>>   print ( diag )  Overfit   Warning                                                                   No  Collinearities                                                                    No  Number   of   Columns   Excluded                                                         3  Perfectly   Collinear   Variables                                                     []  Zero   Trade   Variables               [ importer_fe_IRN ,   importer_fe_LBY ,   importer_fe ...  # Extract the results to a new data frame and save to a .csv  >>>   results_dictionary   =   sample_estimation_model . results_dict ( \"c: \\f older\\saved_results.csv\" )       For more details about the  statsmodels  results object, see  http://www.statsmodels.org/0.6.1/generated/statsmodels.genmod.generalized_linear_model.GLMResults.html .\u00a0 \u21a9",
            "title": "Example"
        },
        {
            "location": "/api_docs/format_regression_table/",
            "text": "Function\n\n\ngme.\nformat_regression_table\n(\nresults_dict:dict = None,\n                             variable_list:List[str] = [],\n                             format:str = 'txt',\n                             se_below:bool = True,\n                             significance_levels:List[float] = [0.1,0.05,0.10],\n                             round_values:int = 3,\n                             omit_fe_prefix:List[str] = [],\n                             table_columns:list = [],\n                             path:str = None,\n                             include_index:bool = False,\n                             latex_syntax:bool = False,\n                             r_squared:bool = False\n):\n\n\nDescription\n\n\nFormat estimation results into a standard table format with options for significance stars, LaTeX syntax, standard error positioning, rounding, fixed effect omission, and others options.\n\n\nArguments\n\n\nresults_dict\n: \nDict[statsmodels.genmod.generalized_linear_model.GLMResultsWrapper]\n \n \u2003 A dictionary of GLM fit objects from statsmodels \n\n\nvariable_list\n: (optional) \nList[str]\n \n \u2003 A list of variables to include in the results table. If none are provided, all variables are included. \n \n \u2003 The default is an empty list, which results in the inclusion of all estimated variables.      \n\n\nformat\n: \nstr\n \n \u2003 Determines the file formatting of text. Accepts 'tex' for LaTeX, 'txt' for plain text, or 'csv' for a \n \n \u2003 csv table. Default is 'txt'. \n\n\nse_below\n: \nbool\n \n \u2003 If True, standard errors are presented below estimates. If False, they are presented in a \n \n \u2003 column to the\nright. The default is True. \n\n\nsignificance_levels\n: \nList[float]\n \n \u2003 A list specifying the three percentages, from lowest to highest, on which to base significance \n \n \u2003 stars. The default value is [0.01, 0.05, 0.10]. \n\n\nround_values\n: \nint\n \n \u2003 The number of decimal points to include in the reported figures. The default is 3. \n\n\nomit_fe_prefix\n: (optional) \nList[str]\n \n \u2003 A list of strings such that any variable starting with that string are omitted from the created \n \n \u2003 table. The value is an empty list that omits no variables.\n\n\ntable_columns\n: (optional) \nList[str]\n \n \u2003 A list of keys from the results_dict to be included in the created table. The default is an empty \n \n \u2003 list, which results in all values being created \n\n\npath\n: (optional) \nstr\n \n \u2003 A system path and file name to write the created table to.  File extensions of .txt (format = 'txt'),\n \n \u2003 .tex or .txt (format = 'tex'), or .csv (format = 'csv') are recommended. \n\n\ninclude_index\n: \nbool\n \n \u2003 If true, the outputed .csv file will contain row numbers. Default is False. \n\n\nlatex_syntax\n: \nbool\n \n \u2003 If true, the table will include LaTeX syntax, regardless of the chosen format. Default is False. \n\n\nvariable_order\n: (optional) \nList[str]\n \n \u2003 If supplied, provides an specific ordering in which to list the variables in the table.\n\n\nr_squared\n:  \nbool\n \n \u2003 If True, it includes R^2 values in the table. This is primarily useful if OLS regression results \n \n \u2003 are supplied. Default is False. \n\n\nReturns\n\n\nReturns:\n \nPandas.DataFrame\n \n \u2003 A DataFrame containing the formatted results table with specified syntax. \n\n\nExamples\n\n\n# Create a .csv file.\n\n\n>>>\n \nsample_estimation_model\n.\nformat_regression_table\n(\nformat\n \n=\n \n'csv'\n,\n\n                                                    \npath\n \n=\n \n\"c:\n\\f\nolder\\saved_results.csv\"\n)\n\n\n\n# Create a LaTeX .tex table without fixed effects (with prefix 'imp_fe_' and 'exp_fe_')\n\n\n>>>\n \nsample_estimation_model\n.\nformat_regression_table\n(\nformat\n \n=\n \n'tex'\n,\n\n\n...\n                                                 \npath\n \n=\n \n\"c:\n\\f\nolder\\saved_results.tex\"\n,\n\n\n...\n                                                 \nomit_fe_prefix\n \n=\n \n[\n'imp_fe_'\n \n,\n \n'exp_fe_'\n])",
            "title": "format_regression_table"
        },
        {
            "location": "/api_docs/format_regression_table/#function",
            "text": "gme. format_regression_table ( results_dict:dict = None,\n                             variable_list:List[str] = [],\n                             format:str = 'txt',\n                             se_below:bool = True,\n                             significance_levels:List[float] = [0.1,0.05,0.10],\n                             round_values:int = 3,\n                             omit_fe_prefix:List[str] = [],\n                             table_columns:list = [],\n                             path:str = None,\n                             include_index:bool = False,\n                             latex_syntax:bool = False,\n                             r_squared:bool = False ):",
            "title": "Function"
        },
        {
            "location": "/api_docs/format_regression_table/#description",
            "text": "Format estimation results into a standard table format with options for significance stars, LaTeX syntax, standard error positioning, rounding, fixed effect omission, and others options.",
            "title": "Description"
        },
        {
            "location": "/api_docs/format_regression_table/#arguments",
            "text": "results_dict :  Dict[statsmodels.genmod.generalized_linear_model.GLMResultsWrapper]  \n \u2003 A dictionary of GLM fit objects from statsmodels   variable_list : (optional)  List[str]  \n \u2003 A list of variables to include in the results table. If none are provided, all variables are included.   \n \u2003 The default is an empty list, which results in the inclusion of all estimated variables.        format :  str  \n \u2003 Determines the file formatting of text. Accepts 'tex' for LaTeX, 'txt' for plain text, or 'csv' for a   \n \u2003 csv table. Default is 'txt'.   se_below :  bool  \n \u2003 If True, standard errors are presented below estimates. If False, they are presented in a   \n \u2003 column to the\nright. The default is True.   significance_levels :  List[float]  \n \u2003 A list specifying the three percentages, from lowest to highest, on which to base significance   \n \u2003 stars. The default value is [0.01, 0.05, 0.10].   round_values :  int  \n \u2003 The number of decimal points to include in the reported figures. The default is 3.   omit_fe_prefix : (optional)  List[str]  \n \u2003 A list of strings such that any variable starting with that string are omitted from the created   \n \u2003 table. The value is an empty list that omits no variables.  table_columns : (optional)  List[str]  \n \u2003 A list of keys from the results_dict to be included in the created table. The default is an empty   \n \u2003 list, which results in all values being created   path : (optional)  str  \n \u2003 A system path and file name to write the created table to.  File extensions of .txt (format = 'txt'),  \n \u2003 .tex or .txt (format = 'tex'), or .csv (format = 'csv') are recommended.   include_index :  bool  \n \u2003 If true, the outputed .csv file will contain row numbers. Default is False.   latex_syntax :  bool  \n \u2003 If true, the table will include LaTeX syntax, regardless of the chosen format. Default is False.   variable_order : (optional)  List[str]  \n \u2003 If supplied, provides an specific ordering in which to list the variables in the table.  r_squared :   bool  \n \u2003 If True, it includes R^2 values in the table. This is primarily useful if OLS regression results   \n \u2003 are supplied. Default is False.",
            "title": "Arguments"
        },
        {
            "location": "/api_docs/format_regression_table/#returns",
            "text": "Returns:   Pandas.DataFrame  \n \u2003 A DataFrame containing the formatted results table with specified syntax.",
            "title": "Returns"
        },
        {
            "location": "/api_docs/format_regression_table/#examples",
            "text": "# Create a .csv file.  >>>   sample_estimation_model . format_regression_table ( format   =   'csv' , \n                                                     path   =   \"c: \\f older\\saved_results.csv\" )  # Create a LaTeX .tex table without fixed effects (with prefix 'imp_fe_' and 'exp_fe_')  >>>   sample_estimation_model . format_regression_table ( format   =   'tex' ,  ...                                                   path   =   \"c: \\f older\\saved_results.tex\" ,  ...                                                   omit_fe_prefix   =   [ 'imp_fe_'   ,   'exp_fe_' ])",
            "title": "Examples"
        },
        {
            "location": "/api_docs/combine_sector_results/",
            "text": "Function\n\n\ncombine_sector_results\n(\nresult_dict:dict = None,\n                            write_path:str = None,\n                            significance_stars: bool = False,\n                            round_results: int = None,\n                            latex_syntax: bool = True\n)\n\n\nDescription\n\n\nExtract key result fields (coefficients, standard errors, and p-values) and combine them in a DataFrame. Has the option to write the data to a .csv file with or without extra value formatting options.\n\n\nArguments\n\n\nresult_dict\n: \nDict[statsmodels.genmod.generalized_linear_model.GLMResultsWrapper]\n \n \u2003 A dictionary of GLM fit objects as returned by gme.EsimationModel.estimate()\n\n\nwrite_path\n: (optional) \nstr\n \n \u2003 A system location and file name in which to write a csv file containing the combined results. \n\n\nsignificance_stars\n: \nbool\n \n \u2003 If true, combined results are output with significance stars. \n <0.01, \n<0.05, and \n<0.10. Default\n \n \u2003 is False.\n\n\nround_results\n: (optional) \nint\n \n \u2003 Rounds combined results to the desired decimal place.\n\n\nlatex_syntax\n: \nbool\n \n \u2003 If True, reports aspects of results, such as significance stars, using standard latex syntax.\n\n\nReturns\n\n\nReturns\n: \nPandas.DataFrame\n \n \u2003 A DataFrame containing combined GLM results for all results in the supplied dictionary.\n\n\nExamples\n\n\n# Using a gme.EstimationModel named 'sample_model'.\n\n\n>>>\n \nsample_results\n \n=\n \nsample_model\n.\nestimate\n()\n\n\n\n# Return a dataframe of results\n\n\n>>>\n \nresult_df\n \n=\n \ncombine_sector_results\n(\nsample_results\n)\n\n\n>>>\n \nresult_df\n.\nhead\n(\n5\n)\n\n                          \nall_coeff\n     \nall_pvalue\n   \nall_stderr\n\n\nlog_distance\n              \n-\n0.739840\n  \n9.318804e-211\n     \n0.023879\n\n\nagree_pta\n                  \n0.334219\n   \n5.134355e-15\n     \n0.042719\n\n\ncommon_language\n            \n0.128770\n   \n1.076932e-03\n     \n0.039383\n\n\ncontiguity\n                 \n0.255161\n   \n5.857612e-08\n     \n0.047050\n\n\nimporter_year_fe_ARG2013\n  \n26.980367\n   \n0.000000e+00\n     \n0.361228\n\n\n\n# Export table as a .csv file\n\n\n>>>\n \ncombine_sector_results\n(\nsample_results\n,\n\n\n...\n                        \nround_results\n \n=\n \n3\n,\n \n\n...\n                        \npath\n \n=\n \n'c:\n\\\\\nDocuments\n\\\\\ncombined_results_saved.csv'\n)",
            "title": "combine_sector_results"
        },
        {
            "location": "/api_docs/combine_sector_results/#function",
            "text": "combine_sector_results ( result_dict:dict = None,\n                            write_path:str = None,\n                            significance_stars: bool = False,\n                            round_results: int = None,\n                            latex_syntax: bool = True )",
            "title": "Function"
        },
        {
            "location": "/api_docs/combine_sector_results/#description",
            "text": "Extract key result fields (coefficients, standard errors, and p-values) and combine them in a DataFrame. Has the option to write the data to a .csv file with or without extra value formatting options.",
            "title": "Description"
        },
        {
            "location": "/api_docs/combine_sector_results/#arguments",
            "text": "result_dict :  Dict[statsmodels.genmod.generalized_linear_model.GLMResultsWrapper]  \n \u2003 A dictionary of GLM fit objects as returned by gme.EsimationModel.estimate()  write_path : (optional)  str  \n \u2003 A system location and file name in which to write a csv file containing the combined results.   significance_stars :  bool  \n \u2003 If true, combined results are output with significance stars.   <0.01,  <0.05, and  <0.10. Default  \n \u2003 is False.  round_results : (optional)  int  \n \u2003 Rounds combined results to the desired decimal place.  latex_syntax :  bool  \n \u2003 If True, reports aspects of results, such as significance stars, using standard latex syntax.",
            "title": "Arguments"
        },
        {
            "location": "/api_docs/combine_sector_results/#returns",
            "text": "Returns :  Pandas.DataFrame  \n \u2003 A DataFrame containing combined GLM results for all results in the supplied dictionary.",
            "title": "Returns"
        },
        {
            "location": "/api_docs/combine_sector_results/#examples",
            "text": "# Using a gme.EstimationModel named 'sample_model'.  >>>   sample_results   =   sample_model . estimate ()  # Return a dataframe of results  >>>   result_df   =   combine_sector_results ( sample_results )  >>>   result_df . head ( 5 ) \n                           all_coeff       all_pvalue     all_stderr  log_distance                - 0.739840    9.318804e-211       0.023879  agree_pta                    0.334219     5.134355e-15       0.042719  common_language              0.128770     1.076932e-03       0.039383  contiguity                   0.255161     5.857612e-08       0.047050  importer_year_fe_ARG2013    26.980367     0.000000e+00       0.361228  # Export table as a .csv file  >>>   combine_sector_results ( sample_results ,  ...                          round_results   =   3 ,   ...                          path   =   'c: \\\\ Documents \\\\ combined_results_saved.csv' )",
            "title": "Examples"
        },
        {
            "location": "/api_docs/load_estimation/",
            "text": "Function\n\n\nload_estimation\n(\nfilename: str\n)\n\n\nDescription\n\n\nLoad a saved estimation model\n\n\nArguments\n\n\nfilename\n: \nstr\n \n \u2003 The path and file name under which an object was saved. \n\n\nReturns\n\n\nReturns\n: \nobject\n \n \u2003 A loaded instance of the specified object. \n\n\nExamples\n\n\n>>>\n \nloaded_model\n \n=\n \nload_estimation\n(\n\"c:\n\\\\\nDocuments\n\\\\\nsaved_object.p\"\n)",
            "title": "load_estimation"
        },
        {
            "location": "/api_docs/load_estimation/#function",
            "text": "load_estimation ( filename: str )",
            "title": "Function"
        },
        {
            "location": "/api_docs/load_estimation/#description",
            "text": "Load a saved estimation model",
            "title": "Description"
        },
        {
            "location": "/api_docs/load_estimation/#arguments",
            "text": "filename :  str  \n \u2003 The path and file name under which an object was saved.",
            "title": "Arguments"
        },
        {
            "location": "/api_docs/load_estimation/#returns",
            "text": "Returns :  object  \n \u2003 A loaded instance of the specified object.",
            "title": "Returns"
        },
        {
            "location": "/api_docs/load_estimation/#examples",
            "text": ">>>   loaded_model   =   load_estimation ( \"c: \\\\ Documents \\\\ saved_object.p\" )",
            "title": "Examples"
        },
        {
            "location": "/api_docs/save_estimation/",
            "text": "Function\n\n\nsave_estimation\n(\nestimation_model, filename: str\n)\n\n\nDescription\n\n\nSave a serialized copy of an EstimationModel or other object at the specified path.\n\n\nArguments\n\n\nestimation_model\n: \nobject\n\n\n The object to be saved. \n\n\nfilename\n: \nstr\n\n\n The path and file name under which to save the object. \n\n\nReturns\n\n\nReturns\n: \nNone\n\n\nExamples\n\n\n>>>\n \nsave_estimation\n(\nsample_model\n,\n \n\"c:\n\\\\\nDocuments\n\\\\\nsaved_object.p\"\n)",
            "title": "save_estimation"
        },
        {
            "location": "/api_docs/save_estimation/#function",
            "text": "save_estimation ( estimation_model, filename: str )",
            "title": "Function"
        },
        {
            "location": "/api_docs/save_estimation/#description",
            "text": "Save a serialized copy of an EstimationModel or other object at the specified path.",
            "title": "Description"
        },
        {
            "location": "/api_docs/save_estimation/#arguments",
            "text": "estimation_model :  object   The object to be saved.   filename :  str   The path and file name under which to save the object.",
            "title": "Arguments"
        },
        {
            "location": "/api_docs/save_estimation/#returns",
            "text": "Returns :  None",
            "title": "Returns"
        },
        {
            "location": "/api_docs/save_estimation/#examples",
            "text": ">>>   save_estimation ( sample_model ,   \"c: \\\\ Documents \\\\ saved_object.p\" )",
            "title": "Examples"
        },
        {
            "location": "/api_docs/SlimResults/",
            "text": "Class\n\n\nSlimResults\n(\nglm_results=None\n)\n\n\nDescription\n\n\nCreate a version of the dictionary of results objects that uses less memory. This is the format of results dictionaries generated under the default options in EstimationModel (i.e. the following argument is executed: \nEstimationModel(..., full_results=False)\n). The SlimResults object is a smaller subset of the GLMResultsWrapper object in the statsmodels package(for more info, see \nstatsmodels' GLMResults\n). Large attributes, such as copies of the estimating data, are removed from the results to cut back on memory size.  The results most commonly referenced are retained, though.\n\n\nThe SlimResults object retains only the attributes listed below. For additional information see the documentation for the GLMResultsWrapper in the statsmodels package.\n\n\nArguments\n\n\nglm_results\n: \nstatsmodels.genmod.generalized_linear_model.GLMResultsWrapper\n \n\n\u2003 An instance of the statsmodels.GLM.fit() results object \n\n\nAtributes\n\n\nparams\n: \nPandas Series\n \n\n \u2003 Estimated parameter values \n\n\naic\n: \nfloat\n \n\n \u2003 Akaike Information Criterion \n\n\nbic\n: \nfloat\n \n\n \u2003 Bayes Information Criterion \n\n\nllf\n: \nfloat\n \n\n \u2003 Value of log-likelihood function \n\n\nnobs\n: \nfloat\n \n\n \u2003 number of observations \n\n\nbse\n: \nPandas Series\n \n\n \u2003 Beta standard errors for parameter estimates \n\n\npvalues\n: \nPandas Series\n \n\n \u2003 Two-tailed pvalues for parameter estimates \n\n\nfamily_name\n: \nstr\n \n\n \u2003 Name of distribution family used \n\n\nfamily_link\n: \nstr\n \n\n \u2003 Estimation link function \n\n\nmethod\n: \nstr\n \n\n \u2003 Estimation method \n\n\nfit_history\n: \nint\n \n\n \u2003 Number of iterations completed \n\n\nscale\n: \nfloat\n \n\n \u2003 The estimate of the scale / dispersion for the model fit \n\n\ndeviance\n: \nfloat\n\n \u2003 Deviance measure \n\n\npearson_chi2\n: \nPandas Series\n \n\n \u2003 Chi-squared statistic \n\n\ncov_type\n: \nstr\n\n \u2003 Covariance type \n\n\nyname\n: \nstr\n\n \u2003 Column name of endogenous variable \n\n\nxname\n: \nList[str]\n\n \u2003 Column names of exogenous variables \n\n\nmodel\n: \nstr\n\n \u2003 Model used for fit \n\n\ndf_resid\n: \nfloat\n\n\ndf_model\n: \nfloat\n\n\ntvalues\n: \nPandas Series\n \n\n\u2003 T statistics\n\n\nfittedvalues\n: \nPandas Series\n \n\n\u2003 Linear predicted values \n\n\nMethods\n\n\nThe SlimResults object replicates two methods from the original GLMResultsWrapper object from statsmodels.\n\n\nconf_int\n: \narray\n\n\n create confidence intervals for parameter estimates. \n\nArguments\n: \n\n\n\u2003 \nalpha\n: (optional) \nfloat\n \n\n\u2003\u2003 The significance level for the confidence interval. \n\n\u2003\u2003 I.e., The default \nalpha\n = .05 returns a 95% confidence interval.\n\n\n\u2003 \ncols\n: (optional) \narray-like\n \n \n\u2003\u2003 \ncols\n specifies which confidence intervals to return\n\n\n\nsummary\n: \nobject\n \n\n\u2003 print a table summarizing estimation results (replicates statsmodels summary method \n\u2003 for GLM).",
            "title": "SlimResults"
        },
        {
            "location": "/api_docs/SlimResults/#class",
            "text": "SlimResults ( glm_results=None )",
            "title": "Class"
        },
        {
            "location": "/api_docs/SlimResults/#description",
            "text": "Create a version of the dictionary of results objects that uses less memory. This is the format of results dictionaries generated under the default options in EstimationModel (i.e. the following argument is executed:  EstimationModel(..., full_results=False) ). The SlimResults object is a smaller subset of the GLMResultsWrapper object in the statsmodels package(for more info, see  statsmodels' GLMResults ). Large attributes, such as copies of the estimating data, are removed from the results to cut back on memory size.  The results most commonly referenced are retained, though.  The SlimResults object retains only the attributes listed below. For additional information see the documentation for the GLMResultsWrapper in the statsmodels package.",
            "title": "Description"
        },
        {
            "location": "/api_docs/SlimResults/#arguments",
            "text": "glm_results :  statsmodels.genmod.generalized_linear_model.GLMResultsWrapper   \n\u2003 An instance of the statsmodels.GLM.fit() results object",
            "title": "Arguments"
        },
        {
            "location": "/api_docs/SlimResults/#atributes",
            "text": "params :  Pandas Series   \n \u2003 Estimated parameter values   aic :  float   \n \u2003 Akaike Information Criterion   bic :  float   \n \u2003 Bayes Information Criterion   llf :  float   \n \u2003 Value of log-likelihood function   nobs :  float   \n \u2003 number of observations   bse :  Pandas Series   \n \u2003 Beta standard errors for parameter estimates   pvalues :  Pandas Series   \n \u2003 Two-tailed pvalues for parameter estimates   family_name :  str   \n \u2003 Name of distribution family used   family_link :  str   \n \u2003 Estimation link function   method :  str   \n \u2003 Estimation method   fit_history :  int   \n \u2003 Number of iterations completed   scale :  float   \n \u2003 The estimate of the scale / dispersion for the model fit   deviance :  float \n \u2003 Deviance measure   pearson_chi2 :  Pandas Series   \n \u2003 Chi-squared statistic   cov_type :  str \n \u2003 Covariance type   yname :  str \n \u2003 Column name of endogenous variable   xname :  List[str] \n \u2003 Column names of exogenous variables   model :  str \n \u2003 Model used for fit   df_resid :  float  df_model :  float  tvalues :  Pandas Series   \n\u2003 T statistics  fittedvalues :  Pandas Series   \n\u2003 Linear predicted values",
            "title": "Atributes"
        },
        {
            "location": "/api_docs/SlimResults/#methods",
            "text": "The SlimResults object replicates two methods from the original GLMResultsWrapper object from statsmodels.  conf_int :  array   create confidence intervals for parameter estimates.  Arguments :   \u2003  alpha : (optional)  float   \n\u2003\u2003 The significance level for the confidence interval.  \n\u2003\u2003 I.e., The default  alpha  = .05 returns a 95% confidence interval.  \u2003  cols : (optional)  array-like    \n\u2003\u2003  cols  specifies which confidence intervals to return  summary :  object   \n\u2003 print a table summarizing estimation results (replicates statsmodels summary method \n\u2003 for GLM).",
            "title": "Methods"
        },
        {
            "location": "/about/",
            "text": "About the GME package\n\n\nThe package was created by the \nGravity Modeling Group\n at the United States International Trade Commission\n\n\nContact us at \ngravity@usitc.gov\n\n\nAdditional information about the development team can be located at the project website at \ngravity.usitc.gov\n.\n\n\nRelease information\n\n\nGME is free, open-source software\n\n\nVersion:\n 1.2\n\n\nDate:\n 10/16/2018",
            "title": "About"
        },
        {
            "location": "/about/#about-the-gme-package",
            "text": "The package was created by the  Gravity Modeling Group  at the United States International Trade Commission  Contact us at  gravity@usitc.gov  Additional information about the development team can be located at the project website at  gravity.usitc.gov .",
            "title": "About the GME package"
        },
        {
            "location": "/about/#release-information",
            "text": "GME is free, open-source software  Version:  1.2  Date:  10/16/2018",
            "title": "Release information"
        }
    ]
}